Device used by pytorch :  cuda
GROUND_TRUTH FOUND :  55
Size of dataset :  55
Size of Trainset :  44
Size of ValidSet :  11
Metaparametres : 
minibatch_size :  1
learning_rate :  0.001
print_every :  70
nb_epoch :  80
MAX_RAM :  850.0


Epoch 1 of 80 Best Validation: 1000000 Time : 78.37154912948608

Epoch 2 of 80 Best Validation: 0.3659541240394717 Time : 179.1864674091339

Epoch 3 of 80 Best Validation: 0.3659541240394717 Time : 257.1722774505615

Epoch 4 of 80 Best Validation: 0.3526079046417667 Time : 357.94383788108826


running_loss:  11.668511005998068
running_loss:  11.991368713736945
running_loss:  12.184058842197471
running_loss:  12.538035265118294
running_loss:  12.602511449665242
running_loss:  12.944444387168103
running_loss:  13.486602956066939
running_loss:  13.770392039428565
running_loss:  13.847869464765402
running_loss:  14.316117787371489
running_loss:  14.657576614628645
running_loss:  14.845910041541272
running_loss:  15.214484780043774
running_loss:  15.3031291281287
running_loss:  15.440747103602105
running_loss:  15.647343743540757
running_loss:  16.0108396177594
running_loss:  16.501484445244486
running_loss:  16.888705230266268
running_loss:  17.45756265836664
running_loss:  17.742371731179038
running_loss:  18.05171853371171
running_loss:  18.1604289611698
running_loss:  18.361129670145193
running_loss:  18.71622139924309
running_loss:  18.98159567230484
running_loss:  19.176497961342744
running_loss:  19.398441091128102
running_loss:  19.484804607410393
running_loss:  19.791079040099344
running_loss:  19.96572824619296
running_loss:  20.153248625600497
running_loss:  20.228327453239917
running_loss:  20.73118142048931

Train_err :  0.2961597345784187
totalValLoss:  3.7387106849087606
running_loss:  0.24679357248047987
running_loss:  0.8019640166312456
running_loss:  1.4244833309203386
running_loss:  1.8387477677315474
running_loss:  2.3947214763611555
running_loss:  2.5607951413840055
running_loss:  2.9710736107081175
running_loss:  3.2015437725931406
running_loss:  3.6308692935854197
running_loss:  3.942338046307365
Epoch 5 of 80 Best Validation: 0.33988278953716006 Time : 459.01957511901855


running_loss:  4.138394436695509
running_loss:  4.64280919627183
running_loss:  4.827542984030313
running_loss:  5.036872581061389
running_loss:  5.112325579341914
running_loss:  5.525190562423732
running_loss:  5.86082923081186
running_loss:  5.942858543660905
running_loss:  6.146752461273636
running_loss:  6.574128642160859
running_loss:  6.961344412941899
running_loss:  7.147362704181836
running_loss:  7.656463191016679
running_loss:  7.872947041359211
running_loss:  8.350676205837063
running_loss:  8.676201906883053
running_loss:  8.892232528473766
running_loss:  9.25618631340977
running_loss:  9.414881847281421
running_loss:  9.732656333078111
running_loss:  9.805365465684895
running_loss:  9.845276877387528
running_loss:  9.913409069283967
running_loss:  10.25829607258654
running_loss:  10.853244155748849
running_loss:  11.41876100676341
running_loss:  11.962608329227399
running_loss:  12.220281792701115
running_loss:  12.591998367156416
running_loss:  12.978796257223516
running_loss:  13.262836457437107
running_loss:  13.551343274509737
running_loss:  13.830672360853184
running_loss:  14.01970367868327
running_loss:  14.192572994468108
running_loss:  14.436213178870574
running_loss:  14.617431590023136
running_loss:  14.689467205821222
running_loss:  15.033634339614457
running_loss:  15.107578438861912
running_loss:  15.669811716354966
running_loss:  16.24340543776957
running_loss:  16.597788321526924
running_loss:  16.995012837203422
Epoch 6 of 80 Best Validation: 0.33988278953716006 Time : 536.9860579967499


running_loss:  17.340698620977083
running_loss:  17.805600009496423
running_loss:  18.162630974884244
running_loss:  18.379658374573204
running_loss:  18.97755149343154
running_loss:  19.305663185452833
running_loss:  19.656545194124593
running_loss:  20.01515713670394
running_loss:  20.235055711999944
running_loss:  20.57011595456343
running_loss:  20.80878874747496
running_loss:  21.204670690879635
running_loss:  21.317498863622955
running_loss:  21.558398306007597
running_loss:  21.956922143335554
running_loss:  22.055411236929807

Train_err :  0.3150773033847115
totalValLoss:  3.7033969555050135
running_loss:  0.06474805623292923
running_loss:  0.5463433439532916
running_loss:  0.9017215246955554
running_loss:  1.184163467337688
running_loss:  1.4721061463157337
running_loss:  2.010319771866004
running_loss:  2.2519543350984654
running_loss:  2.8020158242434263
running_loss:  3.0030780428399644
running_loss:  3.318636297558745
running_loss:  3.389822838517527
running_loss:  3.582495803634326
running_loss:  3.945017950402366
running_loss:  4.441034265276459
running_loss:  4.558427587565449
running_loss:  4.935194068070915
running_loss:  5.323574360873964
running_loss:  5.5103010684251785
running_loss:  5.709787026358147
running_loss:  5.78195945204546
running_loss:  5.8734026327729225
running_loss:  6.434271777669589
running_loss:  6.633094462876519
running_loss:  6.81920453078217
running_loss:  7.002516521244414
running_loss:  7.563629138697353
running_loss:  7.719087738026348
running_loss:  7.995886756210692
Epoch 7 of 80 Best Validation: 0.33667245050045574 Time : 637.9134831428528


running_loss:  8.196708360790378
running_loss:  8.311297977446682
running_loss:  8.368176190286047
running_loss:  8.41522198739565
running_loss:  8.719734525411493
running_loss:  9.19327538781282
running_loss:  9.5761103587639
running_loss:  10.152038450766769
running_loss:  10.60329022579309
running_loss:  10.780660921190348
running_loss:  11.32360049471673
running_loss:  11.442211159918871
running_loss:  11.62854405378716
running_loss:  12.159524927226206
running_loss:  12.260626027360559
running_loss:  12.812329513331255
running_loss:  13.221106414993605
running_loss:  13.563361776371798
running_loss:  13.913949978848299
running_loss:  14.240589157988628
running_loss:  14.462736705938976
running_loss:  14.670305726428827
running_loss:  14.863719798624516
running_loss:  15.243734009563923
running_loss:  15.759592227637768
running_loss:  15.868396789766848
running_loss:  16.213126928545535
running_loss:  16.551752635277808
running_loss:  16.826116375314694
running_loss:  16.99280629089723
running_loss:  17.37851848981033
running_loss:  17.875450612666707
running_loss:  18.162225690049432
running_loss:  18.43668679551532
running_loss:  18.67960145728042
running_loss:  18.901893803539377
running_loss:  19.117821394465864
running_loss:  19.472818839363754
running_loss:  19.700846256067354
running_loss:  20.052182654953665
running_loss:  20.137457790267135
running_loss:  20.315290936993225

Train_err :  0.2902184419570461
totalValLoss:  3.8315336034736696
running_loss:  0.33232101798057556
running_loss:  0.4417136535048485
Epoch 8 of 80 Best Validation: 0.33667245050045574 Time : 727.8783030509949


running_loss:  0.7564054727554321
running_loss:  1.0123090408742428
running_loss:  1.3254697881639004
running_loss:  1.766253681646453
running_loss:  2.0580495426224337
running_loss:  2.536894130624003
running_loss:  2.649143527365393
running_loss:  3.1135698933568268
running_loss:  3.282115505801307
running_loss:  3.4887372905181517
running_loss:  3.8437876755164733
running_loss:  4.034307412906654
running_loss:  4.202561102290121
running_loss:  4.560692872334686
running_loss:  4.747338980539806
running_loss:  4.832648911306428
running_loss:  4.966185026595163
running_loss:  5.07113950026946
running_loss:  5.609373383948373
running_loss:  5.912731553841797
running_loss:  6.129675308345922
running_loss:  6.697786380329895
running_loss:  7.217743207493592
running_loss:  7.339905242849557
running_loss:  7.713118701655834
running_loss:  8.053967925719919
running_loss:  8.550111470433574
running_loss:  8.737290037485462
running_loss:  8.900394496300983
running_loss:  9.168335383240548
running_loss:  9.392953573208716
running_loss:  9.597959025245574
running_loss:  9.913148764624363
running_loss:  9.971568565919167
running_loss:  10.353241812541253
running_loss:  10.718123976244694
running_loss:  11.08817241102871
running_loss:  11.27750841817922
running_loss:  11.818207068989674
running_loss:  12.120515630890925
running_loss:  12.316180109046398
running_loss:  12.381132497452198
running_loss:  12.666341311298309
running_loss:  12.764077064581214
Epoch 9 of 80 Best Validation: 0.33667245050045574 Time : 805.8643271923065


running_loss:  13.215944372220997
running_loss:  13.395519115134244
running_loss:  13.720690198346142
running_loss:  13.792278379305367
running_loss:  13.993313361373211
running_loss:  14.275453560468222
running_loss:  14.792606108304525
running_loss:  14.860943250772024
running_loss:  15.204462637296979
running_loss:  15.364215713873918
running_loss:  15.720593315497453
running_loss:  16.069536567613895
running_loss:  16.24195590765319
running_loss:  16.584836730371332
running_loss:  16.69480911978624
running_loss:  16.875029558574575
running_loss:  17.391368833939648
running_loss:  17.540971917669392
running_loss:  17.740811075860012
running_loss:  17.838448574611295
running_loss:  18.223131311902154
running_loss:  18.29802754630024
running_loss:  18.588986348826435
running_loss:  18.817018079881862

Train_err :  0.26881454399831234
totalValLoss:  3.652050568722188
running_loss:  0.154080493375659
running_loss:  0.32901916228648687
running_loss:  0.5267975897942152
running_loss:  1.0165459915685156
running_loss:  1.3147611448851724
running_loss:  1.4217541942683358
running_loss:  1.7176129127231736
running_loss:  2.2136041526682675
running_loss:  2.4055677191354334
running_loss:  2.664367387536913
running_loss:  2.966715017799288
running_loss:  3.1382507332600653
running_loss:  3.4747627318008907
running_loss:  3.630877220640994
running_loss:  4.149989281108396
running_loss:  4.673099852943172
running_loss:  4.9386940323747694
running_loss:  5.390298656964053
running_loss:  5.671113096022357
running_loss:  6.000893380337705
Epoch 10 of 80 Best Validation: 0.33200459715656255 Time : 906.5185415744781


running_loss:  6.45559555483568
running_loss:  6.689417620551668
running_loss:  7.203418826115214
running_loss:  7.67395473525135
running_loss:  7.837043220849914
running_loss:  8.146327791166387
running_loss:  8.4690257923988
running_loss:  8.662342001218347
running_loss:  8.845796835453559
running_loss:  9.021859059265504
running_loss:  9.359352788111815
running_loss:  9.618660278773556
running_loss:  9.802303939126432
running_loss:  9.873757093213499
running_loss:  10.397970153122312
running_loss:  10.716695530443555
running_loss:  10.881140449705223
running_loss:  11.005499343387783
running_loss:  11.414515326730907
running_loss:  11.54695640038699
running_loss:  11.856045211665332
running_loss:  12.112190244408945
running_loss:  12.359603009186685
running_loss:  12.667285940609872
running_loss:  12.838240048848093
running_loss:  13.286755225621164
running_loss:  13.733419936460754
running_loss:  14.095865976375839
running_loss:  14.20106125312547
running_loss:  14.389079394750299
running_loss:  14.455580848269166
running_loss:  14.994578994500142
running_loss:  15.17477596892665
running_loss:  15.37631723419246
running_loss:  15.556347341069747
running_loss:  15.924164269843866
running_loss:  16.179025531539487
running_loss:  16.48678842631893
running_loss:  16.576345559002625
running_loss:  16.84692665355073
running_loss:  17.417900586293804
running_loss:  17.79344311894642
running_loss:  17.952611038254368
running_loss:  18.008617969022858
Epoch 11 of 80 Best Validation: 0.33200459715656255 Time : 984.707971572876


running_loss:  18.244355297130017
running_loss:  18.408837431834804
running_loss:  18.692162511663305
running_loss:  18.785444354431498
running_loss:  18.945363650098443
running_loss:  19.20474774390459

Train_err :  0.27435353919863703
totalValLoss:  3.3603528489669166
running_loss:  0.17971588065847754
running_loss:  0.6351145246687036
running_loss:  0.8849609458508592
running_loss:  0.9875831940832238
running_loss:  1.1563157797791064
running_loss:  1.4893611916340888
running_loss:  1.7979823113419116
running_loss:  2.3200067044235766
running_loss:  2.429517788036416
running_loss:  2.6784477909095585
running_loss:  2.740258623380214
running_loss:  3.055991050321609
running_loss:  3.1559704644605517
running_loss:  3.4572140894209347
running_loss:  3.8026908657824
running_loss:  3.9557304568588734
running_loss:  4.022548035097619
running_loss:  4.249161175452173
running_loss:  4.797158156211178
running_loss:  5.298683723848727
running_loss:  5.515533151105046
running_loss:  5.856255235150456
running_loss:  6.030509649258521
running_loss:  6.260821504932311
running_loss:  6.451230897050765
running_loss:  6.821756291927563
running_loss:  6.899876978041397
running_loss:  7.136829876444406
running_loss:  7.692808999990423
running_loss:  8.115683834378917
running_loss:  8.57964561941723
running_loss:  8.764974550033608
running_loss:  8.982596842572093
running_loss:  9.3127963822335
running_loss:  9.5760878007859
running_loss:  10.050073681399226
running_loss:  10.259756526599327
running_loss:  10.61841073880593
Epoch 12 of 80 Best Validation: 0.3054866226333561 Time : 1085.9905636310577


running_loss:  10.734381238929927
running_loss:  11.244097841903567
running_loss:  11.468252732314998
running_loss:  12.01177736516628
running_loss:  12.20347803665532
running_loss:  12.406512591573927
running_loss:  12.866208460595873
running_loss:  13.137007162388828
running_loss:  13.329386204895046
running_loss:  13.651601367112663
running_loss:  13.822770358477202
running_loss:  13.93213515304443
running_loss:  14.084033775557247
running_loss:  14.34727245890018
running_loss:  14.507052131721544
running_loss:  14.651567871682346
running_loss:  15.095051507465541
running_loss:  15.253825104174515
running_loss:  15.35066972548763
running_loss:  15.881073801467817
running_loss:  16.30004321245684
running_loss:  16.581533951891796
running_loss:  16.89604277743234
running_loss:  17.15392754930589
running_loss:  17.448294281545614
running_loss:  17.685742608788942
running_loss:  18.018588184896444
running_loss:  18.189679727475678
running_loss:  18.26581606320623
running_loss:  18.55657230866038
running_loss:  18.98599809459928
running_loss:  19.165681981067692

Train_err :  0.2737954568723956
totalValLoss:  3.251746921489636
running_loss:  0.2730238437652588
running_loss:  0.37212271988391876
running_loss:  0.6175063643604517
running_loss:  1.069382855668664
running_loss:  1.3701572809368372
running_loss:  1.4908059779554605
running_loss:  1.8033533876554833
running_loss:  2.0162522938205965
running_loss:  2.3518097235614226
running_loss:  2.688817305749075
running_loss:  2.7797243728095458
running_loss:  2.960787649059461
Epoch 13 of 80 Best Validation: 0.2956133564990578 Time : 1186.7890584468842


running_loss:  3.114094995893538
running_loss:  3.3748537820453444
running_loss:  3.63051589547346
running_loss:  3.746440090239048
running_loss:  3.8295444138348103
running_loss:  4.155443214811385
running_loss:  4.519732960499823
running_loss:  4.7416031220927835
running_loss:  5.04524055795951
running_loss:  5.290079621494645
running_loss:  5.701084577064548
running_loss:  6.210940384512975
running_loss:  6.438461139073803
running_loss:  6.687445803752377
running_loss:  7.051058831831648
running_loss:  7.606109231399994
running_loss:  7.91104143826912
running_loss:  8.101697408594193
running_loss:  8.370030564876895
running_loss:  8.675975812288623
running_loss:  8.841994137503209
running_loss:  8.929185734130444
running_loss:  9.108972554715972
running_loss:  9.410069922916593
running_loss:  9.560233348670106
running_loss:  10.072572099562322
running_loss:  10.16725513080342
running_loss:  10.312321004664733
running_loss:  10.778867130374744
running_loss:  11.254658703899219
running_loss:  11.49841264811241
running_loss:  11.6822560335406
running_loss:  11.738808052510851
running_loss:  12.092396752805346
running_loss:  12.417844476074809
running_loss:  12.869359519850049
running_loss:  12.960981373261246
running_loss:  13.135674600075516
running_loss:  13.358407470294171
running_loss:  13.519121416120067
running_loss:  13.94465064443648
running_loss:  14.186728071421387
running_loss:  14.357293420781694
running_loss:  14.522380489442085
Epoch 14 of 80 Best Validation: 0.2956133564990578 Time : 1264.9491345882416


running_loss:  15.021169309814773
running_loss:  15.16872960670541
running_loss:  15.290212992268307
running_loss:  15.381748518596096
running_loss:  15.905388121803604
running_loss:  16.118372185155753
running_loss:  16.3448312835147
running_loss:  16.626890409116946
running_loss:  16.980070525780324
running_loss:  17.445593947544697
running_loss:  17.718124875798825
running_loss:  18.010123922179147
running_loss:  18.509225829193994
running_loss:  18.806412725398943

Train_err :  0.2686630389342706
totalValLoss:  3.306231583468616
running_loss:  0.5112003137667974
running_loss:  0.6622349056932662
running_loss:  1.0613957573142316
running_loss:  1.2157608796324995
running_loss:  1.4538753260340955
running_loss:  1.7781736995610926
running_loss:  1.9751830798470311
running_loss:  2.3034407299839788
running_loss:  2.3804282274925046
running_loss:  2.5781163702615433
running_loss:  2.735279420287245
running_loss:  2.984261765351726
running_loss:  3.0750634364990725
running_loss:  3.4271607093719973
running_loss:  3.907508302997384
running_loss:  4.202342827390465
running_loss:  4.525944186891946
running_loss:  4.639621896255347
running_loss:  4.860074083838198
running_loss:  5.013041907404032
running_loss:  5.083776229475108
running_loss:  5.372668826435175
running_loss:  5.531381354305066
running_loss:  5.741831321527975
running_loss:  5.780636471023577
running_loss:  6.023101920520681
running_loss:  6.185153642928022
running_loss:  6.500599565243142
running_loss:  6.652192170679984
running_loss:  7.079808395200721
Epoch 15 of 80 Best Validation: 0.2956133564990578 Time : 1355.2887485027313


running_loss:  7.3579945376453315
running_loss:  7.624212249958268
running_loss:  7.7463826796350395
running_loss:  7.909796252381058
running_loss:  8.036505314987155
running_loss:  8.123876992147418
running_loss:  8.395477268379183
running_loss:  8.878538329309475
running_loss:  9.103047922719272
running_loss:  9.42867882968858
running_loss:  9.76472527952865
running_loss:  10.189290475565942
running_loss:  10.66173132431383
running_loss:  10.7736756716234
running_loss:  11.029041734989733
running_loss:  11.446495697678378
running_loss:  11.911272501728188
running_loss:  12.136505107861014
running_loss:  12.44927936124926
running_loss:  12.721115219872447
running_loss:  13.032533056982277
running_loss:  13.186217496740737
running_loss:  13.355683346744629
running_loss:  13.429206370531272
running_loss:  13.635301532689484
running_loss:  13.8641799450852
running_loss:  14.296344154669594
running_loss:  14.441197637520318
running_loss:  14.5150137432437
running_loss:  14.666034554493512
running_loss:  14.80120891834506
running_loss:  15.305636131152927
running_loss:  15.384334162757217
running_loss:  15.714028859769721
running_loss:  15.873439083134551
running_loss:  16.003201494252103
running_loss:  16.48476907409107
running_loss:  16.64550340160107
running_loss:  16.951416462504618
running_loss:  17.266238918372743

Train_err :  0.24666055597675346
totalValLoss:  3.266148814517591
running_loss:  0.20854934118688107
running_loss:  0.37846419939564335
running_loss:  0.6332043109254705
running_loss:  0.7928066183295515
Epoch 16 of 80 Best Validation: 0.2956133564990578 Time : 1445.711666584015


running_loss:  0.9174485061731603
running_loss:  1.05055759065888
running_loss:  1.1861344032093055
running_loss:  1.3861593246563442
running_loss:  1.5235527641553845
running_loss:  1.9203673815872107
running_loss:  2.1623715203151934
running_loss:  2.6009453534562557
running_loss:  2.7688355085233023
running_loss:  2.9759765043337314
running_loss:  3.3952652935663035
running_loss:  3.51263984784277
running_loss:  3.7430461247244646
running_loss:  4.010449427438694
running_loss:  4.491847538027085
running_loss:  4.835881703171052
running_loss:  5.307632379802979
running_loss:  5.621953406008996
running_loss:  5.9025472184746635
running_loss:  6.013303989492771
running_loss:  6.306447608344671
running_loss:  6.497161303439902
running_loss:  6.7023397694445315
running_loss:  7.030602992615766
running_loss:  7.274771334396468
running_loss:  7.809196593032943
running_loss:  8.073901882188188
running_loss:  8.226506711708176
running_loss:  8.401631778520015
running_loss:  8.540582881619533
running_loss:  8.678561939443979
running_loss:  9.184656186546716
running_loss:  9.329990656322074
running_loss:  9.813392516949937
running_loss:  9.877859097698495
running_loss:  10.030686367199651
running_loss:  10.125663008437387
running_loss:  10.231971043989889
running_loss:  10.572304817433984
running_loss:  10.790898907205294
running_loss:  10.89337740672959
running_loss:  11.202106119857891
running_loss:  11.289228291975125
running_loss:  11.535581128464802
Epoch 17 of 80 Best Validation: 0.2956133564990578 Time : 1524.194994688034


running_loss:  11.943776506516667
running_loss:  12.212638753983708
running_loss:  12.417581842487882
running_loss:  12.623081670349668
running_loss:  12.712167980977227
running_loss:  12.817408869870832
running_loss:  12.857474046655824
running_loss:  13.354197588024865
running_loss:  13.88066259005831
running_loss:  14.056916072757705
running_loss:  14.31075561398433
running_loss:  14.475134654384517
running_loss:  14.94061166565451
running_loss:  15.363813792872756
running_loss:  15.748465285739961
running_loss:  15.966617662252647
running_loss:  16.1868534123318
running_loss:  16.471911955417852
running_loss:  16.59396650248931
running_loss:  17.056325699927072
running_loss:  17.194566365279666
running_loss:  17.271996255912295

Train_err :  0.24674280365588994
totalValLoss:  2.9749251752057013
running_loss:  0.14988714394470057
running_loss:  0.4769346608469883
running_loss:  0.621715319653352
running_loss:  0.7574169708208904
running_loss:  0.9909992961006031
running_loss:  1.2066924122886524
running_loss:  1.3406881290591424
running_loss:  1.552143625087208
running_loss:  1.8064238066888516
running_loss:  2.052188822171754
running_loss:  2.4424604262328806
running_loss:  2.75221970035798
running_loss:  2.93392704344458
running_loss:  3.052390013924903
running_loss:  3.1576808310217324
running_loss:  3.214293233222431
running_loss:  3.527790061301655
running_loss:  3.715997335914936
running_loss:  3.8755533294234836
running_loss:  4.006324118986312
running_loss:  4.213148449599329
running_loss:  4.4799517738218935
Epoch 18 of 80 Best Validation: 0.2704477432005183 Time : 1625.118902206421


running_loss:  4.6229818283787205
running_loss:  4.749387927405122
running_loss:  5.122243531100038
running_loss:  5.285723857633355
running_loss:  5.59713639324117
running_loss:  5.831863906286243
running_loss:  5.964910205505374
running_loss:  6.117685901673718
running_loss:  6.475886681479299
running_loss:  6.739750846030398
running_loss:  6.8620869843806656
running_loss:  7.175529423221532
running_loss:  7.353010329469624
running_loss:  7.554676502373897
running_loss:  7.693129855259839
running_loss:  7.96509890542883
running_loss:  8.189556094869557
running_loss:  8.358276976324204
running_loss:  8.477497352338913
running_loss:  8.669308950555408
running_loss:  8.773315539324864
running_loss:  8.831044653171881
running_loss:  8.944110250152235
running_loss:  9.061295298600777
running_loss:  9.15237577047406
running_loss:  9.256291886532887
running_loss:  9.431146160751169
running_loss:  9.553565879818054
running_loss:  10.010697028858383
running_loss:  10.204846741579889
running_loss:  10.618193409664352
running_loss:  10.817696544600446
running_loss:  11.096999415455182
running_loss:  11.211333782670815
running_loss:  11.41827104856364
running_loss:  11.883182508612261
running_loss:  12.360342975447164
running_loss:  12.510487557440586
running_loss:  12.974897927035478
running_loss:  13.291028849935785
running_loss:  13.514143899238363
running_loss:  13.797780528819814
running_loss:  14.290123179710164
running_loss:  14.584109651080027
Epoch 19 of 80 Best Validation: 0.2704477432005183 Time : 1703.2482495307922


running_loss:  15.04778453909482
running_loss:  15.269951297125473
running_loss:  15.555628247507336
running_loss:  15.696329545177939

Train_err :  0.2242332792168277
totalValLoss:  3.103965423173375
running_loss:  0.2703549861907959
running_loss:  0.5559748113155365
running_loss:  0.7151247615822487
running_loss:  0.849730925531023
running_loss:  0.9436231198617153
running_loss:  1.3328481416942344
running_loss:  1.6305275759142306
running_loss:  1.8778648538928893
running_loss:  1.9839493124228385
running_loss:  2.2412457926612763
running_loss:  2.4692005975585847
running_loss:  2.7033427222114472
running_loss:  2.822075692833298
running_loss:  2.9557071569272217
running_loss:  3.1280352267333207
running_loss:  3.222151392967337
running_loss:  3.3716079833813843
running_loss:  3.598157735437983
running_loss:  3.701157922442589
running_loss:  4.091125900443229
running_loss:  4.286301577670707
running_loss:  4.4179508247309265
running_loss:  4.729192172073656
running_loss:  4.852603874686692
running_loss:  4.922607716224674
running_loss:  5.095351720280532
running_loss:  5.525735584656812
running_loss:  5.890815553824521
running_loss:  6.064102274003543
running_loss:  6.196943503442324
running_loss:  6.321967964164085
running_loss:  6.466647195267595
running_loss:  6.83280691333736
running_loss:  7.027009393398961
running_loss:  7.510745637739698
running_loss:  7.715310909940551
running_loss:  8.179486868747821
running_loss:  8.428320595839372
running_loss:  8.685996631005159
running_loss:  8.838688850040652
Epoch 20 of 80 Best Validation: 0.2704477432005183 Time : 1793.6099412441254


running_loss:  8.991147356987415
running_loss:  9.203397496551691
running_loss:  9.672424117672362
running_loss:  10.098229609378098
running_loss:  10.224885397228517
running_loss:  10.552144930335798
running_loss:  10.70101881456665
running_loss:  11.031418625834503
running_loss:  11.281018236600278
running_loss:  11.613249035500406
running_loss:  11.76521490276274
running_loss:  11.933664195032586
running_loss:  12.385231657781537
running_loss:  12.546396551550265
running_loss:  12.695768172128336
running_loss:  13.104405189139978
running_loss:  13.312043012947674
running_loss:  13.687111617065968
running_loss:  13.997241337783636
running_loss:  14.153676961548628
running_loss:  14.387491850492857
running_loss:  14.481941005525492
running_loss:  14.878572611448668
running_loss:  14.922770390597485
running_loss:  15.116711855245136
running_loss:  15.300908435446523
running_loss:  15.402276693688087
running_loss:  15.649189147425611
running_loss:  15.723664672372658
running_loss:  15.875251006593723

Train_err :  0.22678930009419604
totalValLoss:  3.3292622639694147
running_loss:  0.3754003047943115
running_loss:  0.4863952100276947
running_loss:  0.7431608438491821
running_loss:  1.1830792046255536
running_loss:  1.4100533194012113
running_loss:  1.5637208817319739
running_loss:  1.8109379743950236
running_loss:  2.122172406357196
running_loss:  2.2575844139274626
running_loss:  2.4466435006923146
running_loss:  2.6356805672662125
running_loss:  2.7661734788368144
running_loss:  2.8878232731173434
running_loss:  3.093887187540531
Epoch 21 of 80 Best Validation: 0.2704477432005183 Time : 1883.9374628067017


running_loss:  3.3418939858675003
running_loss:  3.726827700932821
running_loss:  4.073999186356863
running_loss:  4.244085889309646
running_loss:  4.442260793099802
running_loss:  4.599552934834114
running_loss:  4.690598690416666
running_loss:  4.8851694650948065
running_loss:  5.207288526826437
running_loss:  5.360292196791208
running_loss:  5.65281600929383
running_loss:  5.8606084546902135
running_loss:  6.117449201539989
running_loss:  6.295717513085242
running_loss:  6.534865150124665
running_loss:  6.599711181492443
running_loss:  6.960362873247102
running_loss:  7.073167423148538
running_loss:  7.43897014582116
running_loss:  7.623639238118714
running_loss:  7.853342778101152
running_loss:  8.08542657721167
running_loss:  8.46904048484026
running_loss:  8.589211104489452
running_loss:  8.76484111701656
running_loss:  8.916731264493949
running_loss:  9.06926811864186
running_loss:  9.18077835771773
running_loss:  9.448237899276949
running_loss:  9.502103663567043
running_loss:  9.624762406055302
running_loss:  10.028720491151846
running_loss:  10.305059789886908
running_loss:  10.776907911420698
running_loss:  10.986835077922379
running_loss:  11.201458618562256
running_loss:  11.505974606196915
running_loss:  11.775432867825861
running_loss:  11.953293279951648
running_loss:  12.01611645633562
running_loss:  12.227484167760448
running_loss:  12.30540378412439
running_loss:  12.50686536718988
running_loss:  12.649709743447604
Epoch 22 of 80 Best Validation: 0.2704477432005183 Time : 1961.9302809238434


running_loss:  12.902008968405427
running_loss:  12.923903572373094
running_loss:  12.97411361243576
running_loss:  13.202791345305743
running_loss:  13.375656903876614
running_loss:  13.552315827614319
running_loss:  13.67850792878825
running_loss:  13.807405411627974
running_loss:  14.20894161058176
running_loss:  14.588526324110314
running_loss:  14.713162661271378
running_loss:  15.150834494839527

Train_err :  0.2164404927834218
totalValLoss:  3.164912277418706
running_loss:  0.2529422756698396
running_loss:  0.4164892063579625
running_loss:  0.5678870582746134
running_loss:  0.727142816202508
running_loss:  0.9533209317467278
running_loss:  1.047511664322681
running_loss:  1.214377286636995
running_loss:  1.4047674261447458
running_loss:  1.513789014166428
running_loss:  2.0003643835791283
running_loss:  2.2887201997348003
running_loss:  2.6883030551382237
running_loss:  2.9716194885679417
running_loss:  3.4084927655963435
running_loss:  3.702221266200973
running_loss:  4.022286734750701
running_loss:  4.297762117555572
running_loss:  4.7554447271136775
running_loss:  4.909413127746019
running_loss:  4.9758954546931715
running_loss:  5.220274669635627
running_loss:  5.390784946477248
running_loss:  5.619898037881487
running_loss:  6.122021629682018
running_loss:  6.288431344243388
running_loss:  6.431575370642046
running_loss:  6.883211757884258
running_loss:  6.992232167058521
running_loss:  7.281151221030289
running_loss:  7.615586728685432
running_loss:  7.764307353542083
running_loss:  7.844145249471897
Epoch 23 of 80 Best Validation: 0.2704477432005183 Time : 2052.2451701164246


running_loss:  8.147279884562725
running_loss:  8.283048268304103
running_loss:  8.466800438757572
running_loss:  8.901942419405612
running_loss:  9.052591191708213
running_loss:  9.276104675709373
running_loss:  9.406317714705235
running_loss:  9.868602926015026
running_loss:  10.02796339440263
running_loss:  10.274600642215875
running_loss:  10.464859294187692
running_loss:  10.621105000169742
running_loss:  10.806790953450319
running_loss:  11.210585580673069
running_loss:  11.407771387603134
running_loss:  11.645818346645683
running_loss:  11.890243248548359
running_loss:  12.278723077382892
running_loss:  12.421496134717017
running_loss:  12.58106875124698
running_loss:  12.85600336925644
running_loss:  13.00027238862175
running_loss:  13.105634312197152
running_loss:  13.245791235369527
running_loss:  13.30351044304876
running_loss:  13.37575080514782
running_loss:  13.406042697735959
running_loss:  13.688321930873725
running_loss:  14.194263098347518
running_loss:  14.374912803578708
running_loss:  14.824901574394769
running_loss:  15.066904970548219
running_loss:  15.33176029763288
running_loss:  15.481988492214844
running_loss:  15.624082731807396
running_loss:  16.07279968354851
running_loss:  16.318471340152126
running_loss:  16.50389209482819

Train_err :  0.23576988706897412
totalValLoss:  3.0486378690434828
running_loss:  0.31782473623752594
running_loss:  0.5119495491186777
running_loss:  0.7333256701628367
running_loss:  0.833577247026066
running_loss:  0.9440785134211183
running_loss:  1.2967335473125179
Epoch 24 of 80 Best Validation: 0.2704477432005183 Time : 2142.345622777939


running_loss:  1.5267577342068155
running_loss:  1.9590607654924193
running_loss:  2.1236832244321704
running_loss:  2.3573817191645503
running_loss:  2.4491255233685174
running_loss:  2.836333252489567
running_loss:  2.9535879641771317
running_loss:  3.0766452557096877
running_loss:  3.2072672188902893
running_loss:  3.3740994771942496
running_loss:  3.554607610218227
running_loss:  3.695759586058557
running_loss:  3.9346569659602313
running_loss:  4.058341543604103
running_loss:  4.178112090668745
running_loss:  4.362841641323435
running_loss:  4.68892400380638
running_loss:  4.882030386891631
running_loss:  5.128531950008539
running_loss:  5.268242588370212
running_loss:  5.523822882626621
running_loss:  5.811431252811519
running_loss:  5.962186764097877
running_loss:  6.132551387055882
running_loss:  6.558706387980946
running_loss:  6.66507794113002
running_loss:  6.969047690689979
running_loss:  7.191401238501487
running_loss:  7.300471010566173
running_loss:  7.502266320348201
running_loss:  7.7056795901411945
running_loss:  8.08119996600888
running_loss:  8.469533679851642
running_loss:  8.9092518313167
running_loss:  9.087712325000515
running_loss:  9.352106570421409
running_loss:  9.52455003771724
running_loss:  9.64417039256336
running_loss:  9.788615056365316
running_loss:  10.067366876691167
running_loss:  10.17279210039932
running_loss:  10.471852415293043
running_loss:  10.890381501107996
running_loss:  11.217305515944545
Epoch 25 of 80 Best Validation: 0.2704477432005183 Time : 2220.5168404579163


running_loss:  11.471002311911436
running_loss:  11.801881293197061
running_loss:  12.150519175403236
running_loss:  12.296794755332588
running_loss:  12.491960076563476
running_loss:  12.906302180089472
running_loss:  13.307007411650073
running_loss:  13.499629804398866
running_loss:  13.673581943692021
running_loss:  14.132734254778676
running_loss:  14.405609783561282
running_loss:  14.538214765851285
running_loss:  14.663645043710456
running_loss:  14.876065447667823
running_loss:  15.067687914137627
running_loss:  15.28386899461556
running_loss:  15.391128120995646
running_loss:  15.67277414729405
running_loss:  15.780673986507788
running_loss:  15.876017241014376

Train_err :  0.22680024630020537
totalValLoss:  2.760248959892326
running_loss:  0.05612265318632126
running_loss:  0.2873338982462883
running_loss:  0.5114407055079937
running_loss:  0.611253522336483
running_loss:  0.7882345064232746
running_loss:  0.8579456495742003
running_loss:  1.0111794203209379
running_loss:  1.2261615369158485
running_loss:  1.346494414222737
running_loss:  1.7045941728477676
running_loss:  1.8445936213764877
running_loss:  2.1851225491199227
running_loss:  2.298212641901854
running_loss:  2.4669240210722716
running_loss:  2.630521995998505
running_loss:  2.7794918697844775
running_loss:  2.9693956058989794
running_loss:  3.113767229693217
running_loss:  3.4754972448055113
running_loss:  3.619286080770608
running_loss:  3.7605785373080933
running_loss:  3.8612141082994635
running_loss:  3.9855166464112695
running_loss:  4.075731502380222
Epoch 26 of 80 Best Validation: 0.25093172362657507 Time : 2321.4220457077026


running_loss:  4.2861338876084325
running_loss:  4.379465805728817
running_loss:  4.73489128275671
running_loss:  4.9010254826603665
running_loss:  5.104301119119757
running_loss:  5.254449744605356
running_loss:  5.427232253261739
running_loss:  5.506867297355914
running_loss:  5.815938222273771
running_loss:  5.924997835161372
running_loss:  6.124990618529006
running_loss:  6.290652548946027
running_loss:  6.499002561024908
running_loss:  6.65407261133401
running_loss:  6.961456568342531
running_loss:  7.259822915463399
running_loss:  7.402249904711629
running_loss:  7.595815079648877
running_loss:  7.978832354717372
running_loss:  8.235064474814056
running_loss:  8.595948209934352
running_loss:  9.068134685616114
running_loss:  9.461026195695418
running_loss:  9.818151347597855
running_loss:  9.986116991533589
running_loss:  10.191678140157213
running_loss:  10.478830817931643
running_loss:  10.650543408002704
running_loss:  10.731401992496103
running_loss:  10.904526484974971
running_loss:  11.229692024954906
running_loss:  11.503738067578524
running_loss:  11.701034357305616
running_loss:  11.762427350040525
running_loss:  11.93623772325615
running_loss:  12.057957215234637
running_loss:  12.171756660565734
running_loss:  12.301420371979475
running_loss:  12.42634353083041
running_loss:  12.558110475954082
running_loss:  12.98113921036323
running_loss:  13.148753828058641
running_loss:  13.399593478689592
running_loss:  13.56719387198488
Epoch 27 of 80 Best Validation: 0.25093172362657507 Time : 2399.5045142173767


running_loss:  13.815327893942596
running_loss:  14.104381105241679

Train_err :  0.2014911586463097
totalValLoss:  3.1982818073075676
running_loss:  0.07642328335593145
running_loss:  0.23078289224455756
running_loss:  0.4749956388647358
running_loss:  0.7000392706443866
running_loss:  0.9596034915496906
running_loss:  1.0938421174262962
running_loss:  1.190065672931572
running_loss:  1.4140633161490164
running_loss:  1.6745720732336244
running_loss:  2.0831272828703127
running_loss:  2.369880363655587
running_loss:  2.498325214100381
running_loss:  2.740997687292596
running_loss:  2.8686770481160946
running_loss:  2.9985460025361843
running_loss:  3.462885879394081
running_loss:  3.7365244854655533
running_loss:  4.151251743651099
running_loss:  4.588702510214515
running_loss:  4.996570843375392
running_loss:  5.17506261335479
running_loss:  5.253004781384436
running_loss:  5.499970562859543
running_loss:  5.640557736779254
running_loss:  5.671405988434952
running_loss:  5.7215613351824395
running_loss:  5.893307223760835
running_loss:  6.207119557851306
running_loss:  6.303212020390979
running_loss:  6.732088636865634
running_loss:  6.915214389510869
running_loss:  7.071704588778733
running_loss:  7.271672029927789
running_loss:  7.406022821501313
running_loss:  7.562190525182007
running_loss:  8.000102940481158
running_loss:  8.117644995761417
running_loss:  8.486378595543407
running_loss:  8.648757459906243
running_loss:  8.830060580434901
running_loss:  9.218476458452646
running_loss:  9.572158409386049
Epoch 28 of 80 Best Validation: 0.25093172362657507 Time : 2489.8185806274414


running_loss:  9.854070717572341
running_loss:  10.078651748701105
running_loss:  10.240665279432307
running_loss:  10.386187922312985
running_loss:  10.76493988072293
running_loss:  11.003249911074011
running_loss:  11.209366229776709
running_loss:  11.3425443806789
running_loss:  11.512252459250806
running_loss:  11.58164094647186
running_loss:  11.714128542950172
running_loss:  11.801424219376514
running_loss:  11.945809955036063
running_loss:  12.160618886610289
running_loss:  12.37253543418936
running_loss:  12.501538269066565
running_loss:  12.780940556743495
running_loss:  12.94681155588478
running_loss:  13.037799618983023
running_loss:  13.13020542993521
running_loss:  13.474691785716765
running_loss:  13.702027583339564
running_loss:  14.031151634382294
running_loss:  14.17678506444726
running_loss:  14.608507432250516
running_loss:  14.732744107229845
running_loss:  14.920915330035822
running_loss:  15.022501247210638

Train_err :  0.2146071606744377
totalValLoss:  2.6791418380000525
running_loss:  0.35961514876948464
running_loss:  0.44036512242423165
running_loss:  0.7514713870154487
running_loss:  0.9033764766322242
running_loss:  1.2267129586802588
running_loss:  1.4835606978999243
running_loss:  1.6379339283125267
running_loss:  1.9410511890633237
running_loss:  2.1200984227988453
running_loss:  2.320849086675379
running_loss:  2.545634802016947
running_loss:  2.7581533657179937
running_loss:  2.9816688464747534
running_loss:  3.1180559549894595
running_loss:  3.1516473595466876
running_loss:  3.286258884032981
Epoch 29 of 80 Best Validation: 0.24355834890909567 Time : 2590.802835702896


running_loss:  3.601942555202792
running_loss:  3.764617387981464
running_loss:  4.063755290737996
running_loss:  4.325711865754177
running_loss:  4.574159865112354
running_loss:  4.711173163882146
running_loss:  5.190055417052159
running_loss:  5.514719232244209
running_loss:  5.674175440592483
running_loss:  5.875597945673183
running_loss:  6.1809442409107245
running_loss:  6.326194727431154
running_loss:  6.4534606591591395
running_loss:  6.7539170377680815
running_loss:  6.8476239510604895
running_loss:  6.901686509553756
running_loss:  7.368159917597141
running_loss:  7.7347631033303
running_loss:  7.867049803646902
running_loss:  8.10969356726855
running_loss:  8.32280856733107
running_loss:  8.438828750099573
running_loss:  8.570884226407442
running_loss:  8.768520992766652
running_loss:  9.025851918669003
running_loss:  9.33966095587756
running_loss:  9.547757055894989
running_loss:  9.56289297929551
running_loss:  9.732041407273048
running_loss:  9.946770414606565
running_loss:  10.066292956290352
running_loss:  10.169180220277566
running_loss:  10.29794122524456
running_loss:  10.689040276506502
running_loss:  10.877900335290986
running_loss:  11.077747291549006
running_loss:  11.304395979865351
running_loss:  11.41410484783248
running_loss:  11.564140587398368
running_loss:  11.749747935656664
running_loss:  11.940812403931178
running_loss:  12.038258081897057
running_loss:  12.152176241985417
running_loss:  12.42904553342507
Epoch 30 of 80 Best Validation: 0.24355834890909567 Time : 2669.0448207855225


running_loss:  12.521193725962398
running_loss:  12.610783588115332
running_loss:  12.807988073650954
running_loss:  13.131248035752732
running_loss:  13.30846064659353
running_loss:  13.409796852282145
running_loss:  13.708041437461766
running_loss:  13.866016476596188
running_loss:  14.054708323622537
running_loss:  14.196683228662652

Train_err :  0.20280976040946644
totalValLoss:  2.9675992574128838
running_loss:  0.24414163827896118
running_loss:  0.35403065717158216
running_loss:  0.5571271959537019
running_loss:  0.6837917450660218
running_loss:  0.8036717541464087
running_loss:  1.0114725150116202
running_loss:  1.3679480371324138
running_loss:  1.6342381318358497
running_loss:  1.9459790219811515
running_loss:  2.0075993766335563
running_loss:  2.159465663626583
running_loss:  2.286345589466186
running_loss:  2.4293080154133753
running_loss:  2.5605585404619986
running_loss:  2.672963371991904
running_loss:  2.827767819424884
running_loss:  3.154299386932204
running_loss:  3.3442311372297504
running_loss:  3.7197213003722327
running_loss:  3.8564377971924837
running_loss:  4.269460136536509
running_loss:  4.4516945703265565
running_loss:  4.7053039575306075
running_loss:  4.884335658668229
running_loss:  5.165450249332934
running_loss:  5.249733541626482
running_loss:  5.384345687460153
running_loss:  5.600636586081236
running_loss:  5.76981551774467
running_loss:  5.874474268251409
running_loss:  6.142540840276827
running_loss:  6.329263726508038
running_loss:  6.420348377329193
running_loss:  6.503357477460263
Epoch 31 of 80 Best Validation: 0.24355834890909567 Time : 2759.3981993198395


running_loss:  6.665453079130707
running_loss:  6.883816155579147
running_loss:  6.992634186184861
running_loss:  7.151008803061106
running_loss:  7.239971227374755
running_loss:  7.3861059544918435
running_loss:  7.628874824123664
running_loss:  7.835794363843484
running_loss:  8.110167049544138
running_loss:  8.25666149214117
running_loss:  8.480423885138912
running_loss:  8.65133278325407
running_loss:  8.735030570895306
running_loss:  9.07951174603982
running_loss:  9.44904389242745
running_loss:  9.68944133952674
running_loss:  9.815876589260167
running_loss:  10.165524917551213
running_loss:  10.341464227582845
running_loss:  10.529680330823693
running_loss:  10.654213642287585
running_loss:  10.964401429105136
running_loss:  11.068700749944481
running_loss:  11.219290767382416
running_loss:  11.447169511165056
running_loss:  11.806246090576881
running_loss:  11.87077305905728
running_loss:  12.153068359372103
running_loss:  12.297452403594637
running_loss:  12.414283393313074
running_loss:  12.716430032574054
running_loss:  12.821037174461203
running_loss:  12.949144566690343
running_loss:  13.09852452043237
running_loss:  13.2484112117543
running_loss:  13.298685140545585

Train_err :  0.18998121629350836
totalValLoss:  2.694718945047094
running_loss:  0.07911941709203853
running_loss:  0.20462205064379507
running_loss:  0.4764039894152019
running_loss:  0.640850380425238
running_loss:  0.8484118286416763
running_loss:  1.0277643803403609
running_loss:  1.1437126245711826
running_loss:  1.333408772609093
Epoch 32 of 80 Best Validation: 0.24355834890909567 Time : 2849.9328866004944


running_loss:  1.4029557873339702
running_loss:  1.5472997744412471
running_loss:  1.6200015910435468
running_loss:  1.6879182545623432
running_loss:  1.8262437669715534
running_loss:  1.9021974740705143
running_loss:  2.058441635919735
running_loss:  2.125857940331722
running_loss:  2.2092646792686232
running_loss:  2.5249854227683195
running_loss:  2.7336231930336603
running_loss:  3.1584436550684685
running_loss:  3.3771766652611808
running_loss:  3.510016825541647
running_loss:  3.756502302855046
running_loss:  3.9142216672448233
running_loss:  3.9581605014649943
running_loss:  4.1493531358687
running_loss:  4.446189248805037
running_loss:  4.600786580419581
running_loss:  4.984183696745377
running_loss:  5.246081707714539
running_loss:  5.412699477462511
running_loss:  5.686952013237815
running_loss:  5.925227743599356
running_loss:  6.112512466523588
running_loss:  6.278125301960648
running_loss:  6.373830289605797
running_loss:  6.694358132081105
running_loss:  6.821164709283038
running_loss:  6.977266159917537
running_loss:  7.303405884834419
running_loss:  7.399197790952812
running_loss:  7.55112659669895
running_loss:  7.81743284798641
running_loss:  7.99275620610246
running_loss:  8.331402558393567
running_loss:  8.465741359809824
running_loss:  8.659827971080729
running_loss:  8.774664700212368
running_loss:  8.87243183658251
running_loss:  9.028924231288125
running_loss:  9.34501127606361
running_loss:  9.451544383877058
Epoch 33 of 80 Best Validation: 0.24355834890909567 Time : 2928.0327928066254


running_loss:  9.53394514060993
running_loss:  9.679021450872014
running_loss:  9.878822955483983
running_loss:  10.123652080565483
running_loss:  10.46665992699046
running_loss:  10.748225205758999
running_loss:  11.027387612680386
running_loss:  11.215544986719678
running_loss:  11.449664565915654
running_loss:  11.523175138229917
running_loss:  11.6492229341788
running_loss:  11.72169546707947
running_loss:  11.97033264226694
running_loss:  12.192813982436846
running_loss:  12.318678314564748
running_loss:  12.498515481827779
running_loss:  12.66565138947529
running_loss:  12.960851291168687

Train_err :  0.18515501844526697
totalValLoss:  2.774293405521247
running_loss:  0.19966023042798042
running_loss:  0.32612400874495506
running_loss:  0.3967432831414044
running_loss:  0.5876190237080058
running_loss:  0.6501481852804621
running_loss:  0.7562135742822041
running_loss:  0.9084340588500103
running_loss:  1.14421875992169
running_loss:  1.3220266423498592
running_loss:  1.4667900560113292
running_loss:  1.777458524486671
running_loss:  1.9350423518464797
running_loss:  2.2087879540502198
running_loss:  2.385332307416118
running_loss:  2.5111308839275606
running_loss:  2.6207043568396733
running_loss:  2.767339902723001
running_loss:  2.963682773316072
running_loss:  3.201550620401071
running_loss:  3.293847842969828
running_loss:  3.37513922020379
running_loss:  3.4610497137117715
running_loss:  3.7134213452744813
running_loss:  3.8180975360381932
running_loss:  3.961906392799897
running_loss:  4.173929822372479
Epoch 34 of 80 Best Validation: 0.24355834890909567 Time : 3018.1891107559204


running_loss:  4.257821815761012
running_loss:  4.336140308891319
running_loss:  4.3774363513932455
running_loss:  4.513659622882389
running_loss:  4.604856085394405
running_loss:  4.690685015533947
running_loss:  4.7797644188524115
running_loss:  4.916673770226124
running_loss:  5.0140297432016165
running_loss:  5.276221493310812
running_loss:  5.441913866800152
running_loss:  5.506000098979307
running_loss:  5.631707409293287
running_loss:  5.715382973715249
running_loss:  5.778571175851135
running_loss:  5.835255249067107
running_loss:  5.985051824374953
running_loss:  6.174264662562766
running_loss:  6.395640732280704
running_loss:  6.51431776283102
running_loss:  6.712461364248561
running_loss:  7.0310078720665645
running_loss:  7.389090581279662
running_loss:  7.71213091765013
running_loss:  7.956061062506504
running_loss:  8.131361054049599
running_loss:  8.426628479527103
running_loss:  8.608428999574649
running_loss:  8.826978120745885
running_loss:  8.938973407985436
running_loss:  9.283265810252892
running_loss:  9.40908608896037
running_loss:  9.933894793813428
running_loss:  10.097906228931
running_loss:  10.250832362876585
running_loss:  10.502290326946726
running_loss:  10.710423352041593
running_loss:  10.869124391271423
running_loss:  11.165242545151463
running_loss:  11.46608825840263
running_loss:  11.57223473215062
running_loss:  11.762143497096583
running_loss:  11.864763758973115
running_loss:  12.062806932462587

Train_err :  0.1723258133208941
totalValLoss:  2.6345665742539697
Epoch 35 of 80 Best Validation: 0.23950605220490634 Time : 3119.3563220500946


running_loss:  0.11356621297697227
running_loss:  0.269722294062376
running_loss:  0.4131426755338907
running_loss:  0.5612733699381351
running_loss:  0.6346492368934883
running_loss:  0.836814620739056
running_loss:  0.9293386627816491
running_loss:  1.0365922803887062
running_loss:  1.1030157227586541
running_loss:  1.223462276522898
running_loss:  1.3293007566179667
running_loss:  1.4556942071972623
running_loss:  1.5447498357130423
running_loss:  1.7772011367811098
running_loss:  1.8462130811272397
running_loss:  1.9787194625371034
running_loss:  2.0486856957173183
running_loss:  2.1154642599220908
running_loss:  2.179716109737961
running_loss:  2.288653404037986
running_loss:  2.471780479471717
running_loss:  2.69500917625717
running_loss:  2.8827705724268324
running_loss:  3.0097639752655394
running_loss:  3.388322068947471
running_loss:  3.617243124741233
running_loss:  3.8389476450263627
running_loss:  3.9523484023391373
running_loss:  4.109946191880024
running_loss:  4.486793310019291
running_loss:  4.722543122816003
running_loss:  4.844529344234616
running_loss:  4.950793942902237
running_loss:  5.31564915785566
running_loss:  5.656322125190248
running_loss:  5.799693677419175
running_loss:  6.039159764690945
running_loss:  6.277347861944387
running_loss:  6.4366960141083425
running_loss:  6.675342834295911
running_loss:  6.9269553189579804
running_loss:  7.177841874719079
running_loss:  7.266553397238668
running_loss:  7.371985879985408
Epoch 36 of 80 Best Validation: 0.23950605220490634 Time : 3197.3280997276306


running_loss:  7.526474282093759
running_loss:  7.642183209252026
running_loss:  7.788330594491627
running_loss:  8.04601409513917
running_loss:  8.127354860254044
running_loss:  8.209289751248432
running_loss:  8.29726469555559
running_loss:  8.366721772045516
running_loss:  8.488656348315997
running_loss:  8.61471693846397
running_loss:  8.827206707326694
running_loss:  8.897197195406381
running_loss:  9.059286493264759
running_loss:  9.228886831008518
running_loss:  9.477702625794336
running_loss:  9.753018327755854
running_loss:  9.905329488916323
running_loss:  9.965682052153474
running_loss:  10.18460761763466
running_loss:  10.355869542884951
running_loss:  10.527302757914489
running_loss:  10.655266007796552
running_loss:  10.865107409216257
running_loss:  11.277884675370943
running_loss:  11.60291998168557
running_loss:  11.874815751255179

Train_err :  0.16964022501793113
totalValLoss:  2.780002407005264
running_loss:  0.15300947722668448
running_loss:  0.2618470347175995
running_loss:  0.3833346224079529
running_loss:  0.4765995076547066
running_loss:  0.6026297444477677
running_loss:  0.9415330349778135
running_loss:  0.9575175068651636
running_loss:  1.2276579366169043
running_loss:  1.365861175995734
running_loss:  1.461875790109237
running_loss:  1.6470722605784733
running_loss:  1.7984437985966601
running_loss:  1.9327451145897308
running_loss:  2.0346989863448672
running_loss:  2.1923907928996615
running_loss:  2.311999190650466
running_loss:  2.436887936718348
running_loss:  2.75855535801707
Epoch 37 of 80 Best Validation: 0.23950605220490634 Time : 3287.8569378852844


running_loss:  3.0317212098485062
running_loss:  3.203660864124281
running_loss:  3.5956681070124934
running_loss:  3.899005315939171
running_loss:  4.110662318507416
running_loss:  4.330024130383713
running_loss:  4.5933765244877165
running_loss:  4.960046715775711
running_loss:  5.245507471004707
running_loss:  5.366316341225885
running_loss:  5.59295978433349
running_loss:  5.712235319169444
running_loss:  5.8058338935693925
running_loss:  5.92503972010066
running_loss:  6.3047106132532145
running_loss:  6.643511589926977
running_loss:  7.011276165023445
running_loss:  7.145545352250337
running_loss:  7.333222720772027
running_loss:  7.474959628035624
running_loss:  7.635236875464518
running_loss:  7.802401545561021
running_loss:  7.8954670352654315
running_loss:  8.119619607925413
running_loss:  8.204197556711732
running_loss:  8.49918961431831
running_loss:  8.650729720247908
running_loss:  8.863882547011597
running_loss:  8.984955561631875
running_loss:  9.091129651112066
running_loss:  9.170832365104513
running_loss:  9.366987764188604
running_loss:  9.443784484717373
running_loss:  9.618417388837162
running_loss:  9.718809872011963
running_loss:  9.945797651152436
running_loss:  10.085690865836415
running_loss:  10.158155694836749
running_loss:  10.256564814830197
running_loss:  10.505324679349236
running_loss:  10.679126211985322
running_loss:  10.802899382620426
running_loss:  11.026825300961109
running_loss:  11.129490851967903
Epoch 38 of 80 Best Validation: 0.23950605220490634 Time : 3365.858733177185


running_loss:  11.373131039681738
running_loss:  11.514866518917387
running_loss:  11.642589332199549
running_loss:  11.845561992040729
running_loss:  11.955484692524701
running_loss:  12.068794484767645
running_loss:  12.186494017899447
running_loss:  12.397071518417858

Train_err :  0.17710102169168368
totalValLoss:  2.5048680281680493
running_loss:  0.3291475302539766
running_loss:  0.5127680551571151
running_loss:  0.684902530318747
running_loss:  0.96494972679971
running_loss:  1.3097435146466727
running_loss:  1.4243677293157413
running_loss:  1.543645026524448
running_loss:  1.665490271885776
running_loss:  1.777712214789871
running_loss:  1.9450733919058825
running_loss:  2.0697010781667715
running_loss:  2.1014326054654604
running_loss:  2.168560302635241
running_loss:  2.4982301697600633
running_loss:  2.697791676269844
running_loss:  2.8048560607712716
running_loss:  2.992500292835757
running_loss:  3.128788987873122
running_loss:  3.1975760423423103
running_loss:  3.519611397214855
running_loss:  3.6689371697139
running_loss:  3.818065172138935
running_loss:  3.905172754881076
running_loss:  4.061805908438854
running_loss:  4.130977888151797
running_loss:  4.300194059058818
running_loss:  4.4451587689367855
running_loss:  4.573910655285647
running_loss:  4.751733356918623
running_loss:  4.821741217579176
running_loss:  5.165027811334262
running_loss:  5.306387751505504
running_loss:  5.538416050413314
running_loss:  5.8407441899568475
running_loss:  5.964903444090549
running_loss:  6.088577328288618
Epoch 39 of 80 Best Validation: 0.22771527528800448 Time : 3466.581081867218


running_loss:  6.167998521006667
running_loss:  6.3162783220177525
running_loss:  6.467077000415885
running_loss:  6.640053606010043
running_loss:  6.766083553006563
running_loss:  6.955950123296741
running_loss:  7.0503649613820025
running_loss:  7.1484459289349624
running_loss:  7.224855864886195
running_loss:  7.332461065767955
running_loss:  7.38767915720948
running_loss:  7.655596462440575
running_loss:  7.7214674887687185
running_loss:  7.815548495505937
running_loss:  7.869060755125248
running_loss:  8.197029482922517
running_loss:  8.30688033621603
running_loss:  8.493005569985447
running_loss:  8.746975686362324
running_loss:  8.92733585178697
running_loss:  9.297201840478618
running_loss:  9.420173921738753
running_loss:  9.505936670285237
running_loss:  9.634637433272374
running_loss:  9.905457216483128
running_loss:  10.063182326977971
running_loss:  10.136148068601164
running_loss:  10.331660663877202
running_loss:  10.528358017573032
running_loss:  10.83729657382032
running_loss:  10.922796897654838
running_loss:  11.109650975157923
running_loss:  11.318638956238932
running_loss:  11.598509303048358

Train_err :  0.16569299004354798
totalValLoss:  2.6718261813124022
running_loss:  0.17414242215454578
running_loss:  0.3739418896536032
running_loss:  0.5057454922546942
running_loss:  0.5636428402115901
running_loss:  0.7968567425592077
running_loss:  0.9251401474595896
running_loss:  1.0563864953712456
running_loss:  1.1759693225742214
running_loss:  1.3135033002019756
running_loss:  1.4241895213619702
Epoch 40 of 80 Best Validation: 0.22771527528800448 Time : 3556.7844829559326


running_loss:  1.5854390248552792
running_loss:  1.715301118687623
running_loss:  1.8376876760481131
running_loss:  1.9296786084046793
running_loss:  2.0129225386901655
running_loss:  2.1057380806628823
running_loss:  2.209209517381775
running_loss:  2.3052041176318503
running_loss:  2.491505930161414
running_loss:  2.728812238162694
running_loss:  2.8556007633839426
running_loss:  2.9322189803157626
running_loss:  3.0980859699581442
running_loss:  3.189422067293587
running_loss:  3.245208843960427
running_loss:  3.3052110191201796
running_loss:  3.491685960791074
running_loss:  3.596926082274877
running_loss:  3.69343014251596
running_loss:  3.786060139575663
running_loss:  3.866358002841783
running_loss:  3.945890012391222
running_loss:  4.039254206426753
running_loss:  4.188434904635264
running_loss:  4.386525661257717
running_loss:  4.442136362699482
running_loss:  4.679839417842838
running_loss:  4.720831074583758
running_loss:  4.955995264605412
running_loss:  5.149853864102624
running_loss:  5.248941498226486
running_loss:  5.450022433095405
running_loss:  5.523939457709073
running_loss:  5.737613878820816
running_loss:  6.057188003931919
running_loss:  6.1880070712908894
running_loss:  6.352648773838559
running_loss:  6.564347946692982
running_loss:  6.666138002325574
running_loss:  6.894889065672436
running_loss:  6.9888356065558686
running_loss:  7.237672079186369
running_loss:  7.327606059546168
running_loss:  7.687722541327174
Epoch 41 of 80 Best Validation: 0.22771527528800448 Time : 3634.831901550293


running_loss:  7.776864739225453
running_loss:  7.978442179129666
running_loss:  8.041087724462463
running_loss:  8.234541125789596
running_loss:  8.370896302357627
running_loss:  8.61454950789145
running_loss:  8.724259824634323
running_loss:  8.79030780291133
running_loss:  8.855524061079551
running_loss:  9.067890840414394
running_loss:  9.36163838470303
running_loss:  9.52045354758027
running_loss:  9.612474857971796
running_loss:  9.730253990183376
running_loss:  9.845627834231385
running_loss:  10.04779643300248

Train_err :  0.14353994904289258
totalValLoss:  2.467122948831982
running_loss:  0.18518019001930952
running_loss:  0.3051099233950178
running_loss:  0.3672820799207936
running_loss:  0.5486372312686096
running_loss:  0.6147965094229828
running_loss:  0.639525421623451
running_loss:  0.7905556994567936
running_loss:  1.0247574548314637
running_loss:  1.2350840270907308
running_loss:  1.2957204737467691
running_loss:  1.374395303001317
running_loss:  1.667230525558504
running_loss:  1.8284916836225118
running_loss:  1.936820305767469
running_loss:  2.0153311293106526
running_loss:  2.1161371383350343
running_loss:  2.254915765253827
running_loss:  2.428746410412714
running_loss:  2.6491392518445434
running_loss:  2.7545946972806834
running_loss:  3.0239148040353836
running_loss:  3.1843452503025116
running_loss:  3.361210136544994
running_loss:  3.5177739414179485
running_loss:  3.571918394675271
running_loss:  3.8266198583878572
running_loss:  4.001536885742098
running_loss:  4.219885013428414
Epoch 42 of 80 Best Validation: 0.2242839044392711 Time : 3735.7162985801697


running_loss:  4.487386963692391
running_loss:  4.663103825774872
running_loss:  4.910752571550095
running_loss:  5.022197927865718
running_loss:  5.209584619436
running_loss:  5.26461149353741
running_loss:  5.35062207069455
running_loss:  5.444732821287795
running_loss:  5.508431227774257
running_loss:  5.571261742980117
running_loss:  5.6429015114489545
running_loss:  5.841900830674504
running_loss:  5.914676075387334
running_loss:  6.080356570788557
running_loss:  6.351667316216563
running_loss:  6.406542990253205
running_loss:  6.4572203230216285
running_loss:  6.660125635202148
running_loss:  6.7363241735794075
running_loss:  6.834586869757106
running_loss:  6.919442630825669
running_loss:  6.9812798244206045
running_loss:  7.054676644478202
running_loss:  7.166495406353434
running_loss:  7.33808025932457
running_loss:  7.569206457404007
running_loss:  7.709543687420795
running_loss:  7.897179522680948
running_loss:  8.104329415726372
running_loss:  8.264150904517415
running_loss:  8.390892187857794
running_loss:  8.51221690236384
running_loss:  8.80827424584681
running_loss:  8.95662011860663
running_loss:  9.187790543901631
running_loss:  9.310551912653157
running_loss:  9.525478423702427
running_loss:  9.61322800618493
running_loss:  9.769205635310048
running_loss:  9.956640431553954
running_loss:  10.043690776814604
running_loss:  10.254354825605535

Train_err :  0.1464907832229362
totalValLoss:  2.4785810964595942
running_loss:  0.0831784582696855
running_loss:  0.14441750788440308
Epoch 43 of 80 Best Validation: 0.2242839044392711 Time : 3825.906625509262


running_loss:  0.300738064882656
running_loss:  0.3932774147639672
running_loss:  0.5230842512100935
running_loss:  0.6341054793447256
running_loss:  0.8205611066271862
running_loss:  0.9628087906166911
running_loss:  1.2293114433478978
running_loss:  1.4472014079284337
running_loss:  1.5680101285171177
running_loss:  1.7531686853100028
running_loss:  1.985979853146192
running_loss:  2.141440667781151
running_loss:  2.3109572703122265
running_loss:  2.417169739285277
running_loss:  2.6776601269634233
running_loss:  2.769450821008326
running_loss:  3.0045631205300904
running_loss:  3.1003149058928505
running_loss:  3.2646694537510887
running_loss:  3.346140000568185
running_loss:  3.4620011690098584
running_loss:  3.582899317986125
running_loss:  3.6300703167216852
running_loss:  3.8097611264351547
running_loss:  3.8823076979283035
running_loss:  3.9568271468419374
running_loss:  4.055318737001572
running_loss:  4.1829300313903435
running_loss:  4.226434496761714
running_loss:  4.284982806912416
running_loss:  4.336393868848164
running_loss:  4.470823270566244
running_loss:  4.553116990085174
running_loss:  4.7496573010640635
running_loss:  4.792797745192527
running_loss:  4.927426145399093
running_loss:  5.15779013651061
running_loss:  5.299929445596516
running_loss:  5.408719176206635
running_loss:  5.645994003435287
running_loss:  5.761912776855752
running_loss:  5.902927267132327
running_loss:  5.974615515908226
running_loss:  6.050735776028079
Epoch 44 of 80 Best Validation: 0.2242839044392711 Time : 3904.1737518310547


running_loss:  6.168343822652888
running_loss:  6.244558609582277
running_loss:  6.402070678330751
running_loss:  6.454226553854015
running_loss:  6.62194547843602
running_loss:  6.7497025657859115
running_loss:  6.828484879677288
running_loss:  6.916213620945605
running_loss:  6.982050262727879
running_loss:  7.130056412295542
running_loss:  7.161621829779405
running_loss:  7.207239200257593
running_loss:  7.2483431630664406
running_loss:  7.30175742530264
running_loss:  7.485774576896802
running_loss:  7.59233283274807
running_loss:  7.634006671762715
running_loss:  7.685406653676182
running_loss:  7.750614953304951
running_loss:  7.811314208452434
running_loss:  7.982321986430583
running_loss:  8.122432700170773
running_loss:  8.268837619074878
running_loss:  8.457775639492965

Train_err :  0.12082536627847093
totalValLoss:  2.4162626457918024
running_loss:  0.24048845326372734
running_loss:  0.3239735938841477
running_loss:  0.3507797975325957
running_loss:  0.5105604358250275
running_loss:  0.5911059852611894
running_loss:  0.8201285750837997
running_loss:  1.1020395955614124
running_loss:  1.3325422606042896
running_loss:  1.467730530964521
running_loss:  1.5552816726396688
running_loss:  1.661247196723707
running_loss:  1.799551162053831
running_loss:  1.8694017409579828
running_loss:  2.022318073664792
running_loss:  2.0960856090532616
running_loss:  2.308809907292016
running_loss:  2.5846030126558617
running_loss:  2.6403006092101955
running_loss:  2.8573815301448726
running_loss:  2.9601000420516357
Epoch 45 of 80 Best Validation: 0.2196602405265275 Time : 4005.079206466675


running_loss:  3.0441182813374326
running_loss:  3.2055343831242578
running_loss:  3.3039673921626265
running_loss:  3.424827918811287
running_loss:  3.5021748323278086
running_loss:  3.6999621022777216
running_loss:  3.833303191168751
running_loss:  3.938918853165685
running_loss:  4.031416829972941
running_loss:  4.091129781406683
running_loss:  4.314468152355403
running_loss:  4.5443676866901415
running_loss:  4.71374599278594
running_loss:  4.8376640855955575
running_loss:  4.9444017610512665
running_loss:  4.99429067208742
running_loss:  5.3127310191695045
running_loss:  5.516841415264125
running_loss:  5.5969321689982365
running_loss:  5.947250829647397
running_loss:  6.001079512397861
running_loss:  6.1270151681059755
running_loss:  6.323558742439166
running_loss:  6.407075891529933
running_loss:  6.665369278078691
running_loss:  6.929975422771854
running_loss:  7.075595303179902
running_loss:  7.217704374394896
running_loss:  7.341878743583543
running_loss:  7.478960500771386
running_loss:  7.6773078709116405
running_loss:  7.749915630608382
running_loss:  7.994847492366614
running_loss:  8.16667964780289
running_loss:  8.23291224743136
running_loss:  8.274586863350121
running_loss:  8.38431881383682
running_loss:  8.611964237100132
running_loss:  8.660812897918122
running_loss:  8.707292950401701
running_loss:  8.855100667725004
running_loss:  9.108767575273909
running_loss:  9.267925402770437
running_loss:  9.334876850713043
Epoch 46 of 80 Best Validation: 0.2196602405265275 Time : 4083.2069866657257


running_loss:  9.566547996519752
running_loss:  9.63161848989936
running_loss:  9.714662460066997
running_loss:  10.029283344823243
running_loss:  10.244094557723855
running_loss:  10.414286227560495

Train_err :  0.1487755175365785
totalValLoss:  3.2543513989076023
running_loss:  0.29924250145753223
running_loss:  0.6140207201242447
running_loss:  0.7541271168738604
running_loss:  1.2052108962088823
running_loss:  1.3674442890721064
running_loss:  1.7753365659154952
running_loss:  1.87943183677271
running_loss:  1.943269813278069
running_loss:  2.0789885571381697
running_loss:  2.1190930804392942
running_loss:  2.3999784192225584
running_loss:  2.530066869687289
running_loss:  2.6953611481003463
running_loss:  2.883749659638852
running_loss:  2.9678093172454587
running_loss:  3.105392021670317
running_loss:  3.2395734067540616
running_loss:  3.2956324861022748
running_loss:  3.3891648378792323
running_loss:  3.4487842278710255
running_loss:  3.5973268741896995
running_loss:  3.7254864912635335
running_loss:  3.891776342332984
running_loss:  3.983064457347306
running_loss:  4.201605104414435
running_loss:  4.301296213641762
running_loss:  4.361479978697995
running_loss:  4.452927870055039
running_loss:  4.728077245255311
running_loss:  4.834381882411738
running_loss:  4.953595424070954
running_loss:  5.047959516652757
running_loss:  5.078660686396891
running_loss:  5.238473799907499
running_loss:  5.3567996890180645
running_loss:  5.492419655952189
running_loss:  5.556075240537111
running_loss:  5.720412622257654
Epoch 47 of 80 Best Validation: 0.2196602405265275 Time : 4173.721639633179


running_loss:  5.867047908767645
running_loss:  5.935347193593367
running_loss:  6.016535265733386
running_loss:  6.055481082966759
running_loss:  6.144138651175632
running_loss:  6.205362094113501
running_loss:  6.370049587515598
running_loss:  6.444835240862126
running_loss:  6.527263848098099
running_loss:  6.673273919137299
running_loss:  6.780847796536465
running_loss:  6.86483163447378
running_loss:  6.894323521073804
running_loss:  7.061252333935246
running_loss:  7.123538793310419
running_loss:  7.158685395377687
running_loss:  7.239318434498272
running_loss:  7.271129919138426
running_loss:  7.312787725822999
running_loss:  7.411036855773999
running_loss:  7.635759431170299
running_loss:  7.7455528259743
running_loss:  7.78860561462352
running_loss:  7.846866066781027
running_loss:  8.00260035249327
running_loss:  8.127997945276244
running_loss:  8.181243908339335
running_loss:  8.42677019231875
running_loss:  8.52847562348082
running_loss:  8.592842873088859
running_loss:  8.765847201944172
running_loss:  8.87306508749801

Train_err :  0.126758072678543
totalValLoss:  2.430711304458479
running_loss:  0.1254032338038087
running_loss:  0.26885843742638826
running_loss:  0.43294771129472387
running_loss:  0.6358137142120136
running_loss:  0.7198375915694568
running_loss:  0.9224321021594936
running_loss:  0.9999214037218028
running_loss:  1.0533196470286283
running_loss:  1.2234836191249392
running_loss:  1.308615266190221
running_loss:  1.366983610050132
running_loss:  1.4713549895289666
Epoch 48 of 80 Best Validation: 0.2196602405265275 Time : 4264.029100418091


running_loss:  1.605644671440435
running_loss:  1.80732311141522
running_loss:  1.8836742056300866
running_loss:  1.9403012044883026
running_loss:  2.003669092819716
running_loss:  2.0909739238365246
running_loss:  2.1432945810956885
running_loss:  2.2699567528519164
running_loss:  2.396717760129832
running_loss:  2.4653897240447504
running_loss:  2.5335304963583543
running_loss:  2.598007312962889
running_loss:  2.6515835809081585
running_loss:  2.7097074342762224
running_loss:  2.8313926374410383
running_loss:  2.98125429419128
running_loss:  3.0458258972891294
running_loss:  3.0850014547274136
running_loss:  3.2020661116241373
running_loss:  3.307650141663746
running_loss:  3.3612416389061965
running_loss:  3.5617355855776824
running_loss:  3.620100815560565
running_loss:  3.752429310943828
running_loss:  3.784040529319706
running_loss:  3.8178126650940003
running_loss:  4.054388223875624
running_loss:  4.098832308508766
running_loss:  4.262935214869988
running_loss:  4.455633023016465
running_loss:  4.503365474947107
running_loss:  4.603668114015211
running_loss:  4.668847457350542
running_loss:  4.772112377764036
running_loss:  4.876111353592326
running_loss:  5.0425146978814155
running_loss:  5.124300505474417
running_loss:  5.2011403571167545
running_loss:  5.3196317189657645
running_loss:  5.574751012893911
running_loss:  5.741903023212217
running_loss:  5.808628657121314
running_loss:  5.914939821917667
running_loss:  5.999217880178346
Epoch 49 of 80 Best Validation: 0.2196602405265275 Time : 4342.3124458789825


running_loss:  6.077845798249149
running_loss:  6.238882662172222
running_loss:  6.405545545185709
running_loss:  6.597586120853925
running_loss:  6.6590801523869025
running_loss:  6.736234185272931
running_loss:  6.863840912455796
running_loss:  6.895336715413982
running_loss:  6.9919767648938835
running_loss:  7.101565618908757
running_loss:  7.122534436083192
running_loss:  7.178990596678988
running_loss:  7.308214748051897
running_loss:  7.370885749121145

Train_err :  0.10529836784458779
totalValLoss:  2.2996039164976945
running_loss:  0.06674153078347445
running_loss:  0.1665646679078539
running_loss:  0.25970433217783767
running_loss:  0.4364821420361598
running_loss:  0.5610829363059666
running_loss:  0.6347878572738005
running_loss:  0.672767071881228
running_loss:  0.8507476252400212
running_loss:  0.9174135317767246
running_loss:  0.9495864732048681
running_loss:  1.0387277231719863
running_loss:  1.0867462229151796
running_loss:  1.1175976738191418
running_loss:  1.283163239047604
running_loss:  1.332120185000046
running_loss:  1.3519668159036278
running_loss:  1.44341525994888
running_loss:  1.5280105527555055
running_loss:  1.5770412678118901
running_loss:  1.6575390162631976
running_loss:  1.7079661870439953
running_loss:  1.9452548408945507
running_loss:  2.0019173119281835
running_loss:  2.1098104758873686
running_loss:  2.24913451200377
running_loss:  2.4255463642443322
running_loss:  2.581820032410582
running_loss:  2.644301390320632
running_loss:  2.9118524250095814
running_loss:  2.9813940125815055
Epoch 50 of 80 Best Validation: 0.20905490149979042 Time : 4443.397574424744


running_loss:  3.0891634972132227
running_loss:  3.220867395006483
running_loss:  3.429784059130018
running_loss:  3.7182687815058877
running_loss:  3.7638483554215383
running_loss:  3.8257900600955415
running_loss:  3.8914051096588897
running_loss:  4.05605474521225
running_loss:  4.132945913853797
running_loss:  4.231610954538661
running_loss:  4.3362204791628765
running_loss:  4.35198001243407
running_loss:  4.393983085387543
running_loss:  4.462393683129147
running_loss:  4.515082047999993
running_loss:  4.616978504442766
running_loss:  4.874960758471087
running_loss:  4.914139309762202
running_loss:  4.960941972540848
running_loss:  5.012318785166524
running_loss:  5.112614115253868
running_loss:  5.194978249744358
running_loss:  5.253652189877662
running_loss:  5.3598399022788135
running_loss:  5.486319542881879
running_loss:  5.536051639918394
running_loss:  5.673709014061995
running_loss:  5.69798245510578
running_loss:  5.832447786938348
running_loss:  5.964048437819455
running_loss:  6.011420294842943
running_loss:  6.047450714686422
running_loss:  6.149192166301268
running_loss:  6.209264710099283
running_loss:  6.3251526900761155
running_loss:  6.367546955666817
running_loss:  6.465069825372971
running_loss:  6.530689168087622
running_loss:  6.723660883791228
running_loss:  6.835874128659878

Train_err :  0.09765534469514112
totalValLoss:  2.306740964659386
running_loss:  0.03956373998274406
running_loss:  0.12044585084853074
running_loss:  0.15382704751876494
running_loss:  0.21887353986191255
Epoch 51 of 80 Best Validation: 0.20905490149979042 Time : 4533.671507835388


running_loss:  0.2546242171406953
running_loss:  0.28295827840661836
running_loss:  0.3386258773712648
running_loss:  0.40617579847781193
running_loss:  0.43800933342168313
running_loss:  0.48752554018412614
running_loss:  0.634514334391699
running_loss:  0.7517141027815847
running_loss:  0.7955503762415093
running_loss:  0.8630137500068586
running_loss:  0.9696920930226851
running_loss:  1.0009077793349408
running_loss:  1.1483899062861584
running_loss:  1.1983276388038777
running_loss:  1.280890612733654
running_loss:  1.3003596745483164
running_loss:  1.4744511775724176
running_loss:  1.5361982867018216
running_loss:  1.5839165173367493
running_loss:  1.6306106821996056
running_loss:  1.8007330523234688
running_loss:  1.8583941898282823
running_loss:  1.9851976295596816
running_loss:  2.0366211047059752
running_loss:  2.1093369117912113
running_loss:  2.1638328537163845
running_loss:  2.2923279247996917
running_loss:  2.3256201578511133
running_loss:  2.5135065151585474
running_loss:  2.5623447260715895
running_loss:  2.6756308609749087
running_loss:  2.7875030199195154
running_loss:  2.912917665218831
running_loss:  2.9611565393990733
running_loss:  3.1533665431327083
running_loss:  3.250057794347716
running_loss:  3.3723878713402278
running_loss:  3.4080450069547323
running_loss:  3.4688918227717904
running_loss:  3.543941948601666
running_loss:  3.623640080719876
running_loss:  3.66254695757137
running_loss:  3.690886649186723
running_loss:  3.7242904376471415
Epoch 52 of 80 Best Validation: 0.20905490149979042 Time : 4611.888436794281


running_loss:  3.8203009251737967
running_loss:  3.981031957664527
running_loss:  4.100943445603156
running_loss:  4.18709948417058
running_loss:  4.274210106568514
running_loss:  4.440224032836138
running_loss:  4.5535811676204
running_loss:  4.656739785012582
running_loss:  4.7149671695531445
running_loss:  4.869439833551748
running_loss:  4.916863401601504
running_loss:  5.053736159345134
running_loss:  5.204192382982
running_loss:  5.4229931458054725
running_loss:  5.6091456422194215
running_loss:  5.903230934985913
running_loss:  6.175305987359025
running_loss:  6.4111214528093114
running_loss:  6.511902162688784
running_loss:  6.672476672451012
running_loss:  6.854753254485938
running_loss:  7.072161915285203

Train_err :  0.10103088450407433
totalValLoss:  2.9061810165229773
running_loss:  0.10580542268386732
running_loss:  0.15437120529046905
running_loss:  0.4251808544698482
running_loss:  0.48617337052969056
running_loss:  0.5745897511434224
running_loss:  0.8104859109347065
running_loss:  0.9930573667710025
running_loss:  1.2722552086537082
running_loss:  1.3870175248011947
running_loss:  1.6479336386546493
running_loss:  1.7734985826537013
running_loss:  1.8574581257998943
running_loss:  1.9229936483316123
running_loss:  2.0223905104212463
running_loss:  2.240061357151717
running_loss:  2.3940903584783277
running_loss:  2.5350752885763845
running_loss:  2.735518005055686
running_loss:  2.78572652147462
running_loss:  3.1715856078598237
running_loss:  3.2976529929373
running_loss:  3.5498271890812454
Epoch 53 of 80 Best Validation: 0.20905490149979042 Time : 4702.206109046936


running_loss:  3.8383875379545827
running_loss:  3.947049755810036
running_loss:  4.106378491165945
running_loss:  4.212206428430768
running_loss:  4.297217076204511
running_loss:  4.349308028066946
running_loss:  4.512605815375639
running_loss:  4.57428235854281
running_loss:  4.739541670449803
running_loss:  4.8932884239151875
running_loss:  4.979814642251263
running_loss:  5.084655081064234
running_loss:  5.158007994009597
running_loss:  5.309080527759055
running_loss:  5.438452527211567
running_loss:  5.524876304462347
running_loss:  5.689237542941961
running_loss:  5.743319502902322
running_loss:  5.824553777916462
running_loss:  5.908959392988538
running_loss:  6.065708025578514
running_loss:  6.232890471104637
running_loss:  6.441058005426184
running_loss:  6.581380180613553
running_loss:  6.706881674226478
running_loss:  6.842966201003746
running_loss:  7.052017675932602
running_loss:  7.098681898076192
running_loss:  7.239818112213269
running_loss:  7.409453065354482
running_loss:  7.513577786494151
running_loss:  7.699345124174014
running_loss:  7.734365385504337
running_loss:  7.7954152263830325
running_loss:  7.8378007935179
running_loss:  7.972516467962933
running_loss:  8.021639703630678
running_loss:  8.078253584461184
running_loss:  8.147171584436567
running_loss:  8.297007852091662
running_loss:  8.357517648035557
running_loss:  8.528286607328079
running_loss:  8.6666502071053
running_loss:  8.797939496127785
Epoch 54 of 80 Best Validation: 0.20905490149979042 Time : 4780.136639356613


running_loss:  8.959265011065225
running_loss:  9.098589397565876
running_loss:  9.242379344598804
running_loss:  9.310219299371562

Train_err :  0.13300313284816517
totalValLoss:  2.102507472762631
running_loss:  0.02390272542834282
running_loss:  0.11497840782006581
running_loss:  0.2504021941373746
running_loss:  0.30877736024558544
running_loss:  0.35597132712913054
running_loss:  0.42155768217829365
running_loss:  0.5918829465129722
running_loss:  0.6456737172945092
running_loss:  0.9026440930708001
running_loss:  0.9666389770573005
running_loss:  1.1881237871712074
running_loss:  1.2819935656023316
running_loss:  1.3381565099763166
running_loss:  1.4088006962815092
running_loss:  1.4559007333074179
running_loss:  1.5760718704615202
running_loss:  1.6394309779732592
running_loss:  1.7721909066765673
running_loss:  1.8201678211593795
running_loss:  1.8765221302811472
running_loss:  1.9651416828338473
running_loss:  2.0239581940178244
running_loss:  2.0650319170155047
running_loss:  2.0922271495866074
running_loss:  2.1883842297700338
running_loss:  2.240606368972092
running_loss:  2.2583499727123937
running_loss:  2.383339496206544
running_loss:  2.5016846862401714
running_loss:  2.538336572696507
running_loss:  2.58311516651237
running_loss:  2.610951973041261
running_loss:  2.7384390662514813
running_loss:  2.8005710341126866
running_loss:  2.8759538330228276
running_loss:  2.9173854173018805
running_loss:  2.9962395395009986
running_loss:  3.0954150783687107
running_loss:  3.178174987700509
running_loss:  3.223144654837799
Epoch 55 of 80 Best Validation: 0.191137042978421 Time : 4880.8694705963135


running_loss:  3.3036833242319212
running_loss:  3.3475751458706022
running_loss:  3.3754155520000495
running_loss:  3.408870547583016
running_loss:  3.6014048899911963
running_loss:  3.689306119030031
running_loss:  3.7216404003168764
running_loss:  3.887005053188962
running_loss:  4.003456391122502
running_loss:  4.02050231428196
running_loss:  4.083824328922977
running_loss:  4.1128105209209025
running_loss:  4.16171847213991
running_loss:  4.189295115337397
running_loss:  4.251320142066106
running_loss:  4.29457417378823
running_loss:  4.448924678067367
running_loss:  4.4736508703790605
running_loss:  4.528652764908555
running_loss:  4.583210268109623
running_loss:  4.635340733919293
running_loss:  4.72508623158016
running_loss:  4.76655941605956
running_loss:  4.891696596149511
running_loss:  4.934681962768082
running_loss:  4.976395305045622
running_loss:  5.027876488935565
running_loss:  5.184397749673938
running_loss:  5.224296773156514
running_loss:  5.26903874240169

Train_err :  0.07527198203430985
totalValLoss:  2.3246604009117515
running_loss:  0.09391221776604652
running_loss:  0.17386566164592904
running_loss:  0.21394689784695706
running_loss:  0.3313731815045079
running_loss:  0.5101619775717458
running_loss:  0.5385491159395315
running_loss:  0.671051403565798
running_loss:  0.7009496477937015
running_loss:  0.7309461565261396
running_loss:  0.7456355082168657
running_loss:  0.7707452602205901
running_loss:  0.8077890257700345
running_loss:  0.9412185530527494
running_loss:  0.9984971835510804
Epoch 56 of 80 Best Validation: 0.191137042978421 Time : 4971.245543003082


running_loss:  1.008487246115692
running_loss:  1.023380376631394
running_loss:  1.0866319002234377
running_loss:  1.1193239178262755
running_loss:  1.1858056737692095
running_loss:  1.2142999579470295
running_loss:  1.282830087888417
running_loss:  1.3619740432606908
running_loss:  1.5074909305678579
running_loss:  1.5325615672562791
running_loss:  1.5595721456468004
running_loss:  1.577350296707462
running_loss:  1.6779520070865857
running_loss:  1.7161058398649203
running_loss:  1.9104206624195086
running_loss:  1.9612671310767638
running_loss:  2.1130651558503617
running_loss:  2.181114371562015
running_loss:  2.2096174627529566
running_loss:  2.310320359467167
running_loss:  2.34784629247022
running_loss:  2.390566587079472
running_loss:  2.47219196689548
running_loss:  2.4965998793680537
running_loss:  2.512961374123633
running_loss:  2.5922916370844993
running_loss:  2.6828784800535592
running_loss:  2.7707071385747346
running_loss:  2.8005602068668756
running_loss:  2.8509828083850968
running_loss:  2.8977618998550403
running_loss:  2.9618344817944395
running_loss:  2.991611507384935
running_loss:  3.018461468642475
running_loss:  3.138712872763993
running_loss:  3.208088886937024
running_loss:  3.2369209681766944
running_loss:  3.2936612578859146
running_loss:  3.3346619267960915
running_loss:  3.4857894700964818
running_loss:  3.52296456228295
running_loss:  3.5745108872587386
running_loss:  3.619352453381807
running_loss:  3.641407998485698
Epoch 57 of 80 Best Validation: 0.191137042978421 Time : 5049.37091255188


running_loss:  3.6741367197181622
running_loss:  3.7141680278711857
running_loss:  3.7397588622536415
running_loss:  3.8559439909424538
running_loss:  3.873698632174638
running_loss:  3.941969375067857
running_loss:  3.972210473206361
running_loss:  4.025787361050284
running_loss:  4.087884657479461
running_loss:  4.117836224154518
running_loss:  4.146714804726394
running_loss:  4.208027660908152

Train_err :  0.060114680870116455
totalValLoss:  2.434401694840441
running_loss:  0.02097943580398957
running_loss:  0.06408191627512376
running_loss:  0.07937477924861014
running_loss:  0.11152926630650958
running_loss:  0.19704568556820354
running_loss:  0.29921909592424834
running_loss:  0.41672139040504896
running_loss:  0.45248028061663115
running_loss:  0.4856844682556888
running_loss:  0.51000178217267
running_loss:  0.5367807438597083
running_loss:  0.6006989586167037
running_loss:  0.650657547172159
running_loss:  0.7456821850501001
running_loss:  0.7929007657803595
running_loss:  0.8147841130266897
running_loss:  0.8340240396404018
running_loss:  1.0092303134345761
running_loss:  1.0368862488798591
running_loss:  1.0969632242211245
running_loss:  1.1336804444306634
running_loss:  1.2058351860873195
running_loss:  1.2356927097231771
running_loss:  1.277405387760761
running_loss:  1.3648016816393163
running_loss:  1.4242776569574038
running_loss:  1.4499739923178117
running_loss:  1.5104725544935922
running_loss:  1.5720012057119879
running_loss:  1.5974234611817844
running_loss:  1.624269498214643
running_loss:  1.7487513773893524
Epoch 58 of 80 Best Validation: 0.191137042978421 Time : 5139.59344625473


running_loss:  1.9543640666460205
running_loss:  1.9863419017573405
running_loss:  2.027646097005345
running_loss:  2.0940709734568372
running_loss:  2.132739086635411
running_loss:  2.2100512804463506
running_loss:  2.2699503349140286
running_loss:  2.3577226595953107
running_loss:  2.3881106974764004
running_loss:  2.527707591859831
running_loss:  2.540797976809295
running_loss:  2.5970325737273217
running_loss:  2.6256109687512637
running_loss:  2.660958807404515
running_loss:  2.732389040711698
running_loss:  2.758360485908472
running_loss:  2.8398301384618714
running_loss:  2.869657378191025
running_loss:  2.9168093013706513
running_loss:  2.9817981757352956
running_loss:  3.0085437420186483
running_loss:  3.030167769323776
running_loss:  3.1274498064627148
running_loss:  3.1781227025138734
running_loss:  3.2194802625971435
running_loss:  3.2528338988712577
running_loss:  3.2745729495396114
running_loss:  3.288212535016808
running_loss:  3.317702945367071
running_loss:  3.3680777975759058
running_loss:  3.3923136228954216
running_loss:  3.426683992018096
running_loss:  3.5474585069912594
running_loss:  3.6566923184889477
running_loss:  3.676082428046761
running_loss:  3.6923626656320674
running_loss:  3.710691760921489
running_loss:  3.738856031643486

Train_err :  0.05341222902347837
totalValLoss:  2.451861946183878
running_loss:  0.030824939953163266
running_loss:  0.04588372993748635
running_loss:  0.06077948159589949
running_loss:  0.08218448484290598
running_loss:  0.10185942410155097
running_loss:  0.1270458407751802
Epoch 59 of 80 Best Validation: 0.191137042978421 Time : 5229.808123111725


running_loss:  0.18839929700415167
running_loss:  0.21398565250112572
running_loss:  0.2617771522038513
running_loss:  0.3987278387778335
running_loss:  0.42650299508952433
running_loss:  0.45445617394418353
running_loss:  0.4750043524868993
running_loss:  0.6080095990069417
running_loss:  0.6537133821726052
running_loss:  0.6660223640630849
running_loss:  0.7505675628910669
running_loss:  0.7718298063587604
running_loss:  0.7865863966225233
running_loss:  0.8038657563479824
running_loss:  0.8243019425944011
running_loss:  0.8463835247417187
running_loss:  0.8627402206798757
running_loss:  0.8803272447193093
running_loss:  0.9254047403066782
running_loss:  0.9549987394162196
running_loss:  0.9751435655279138
running_loss:  0.991915096881308
running_loss:  1.0088719514347355
running_loss:  1.042104303199772
running_loss:  1.084449098636267
running_loss:  1.133826391030905
running_loss:  1.1456648244671266
running_loss:  1.1871636009923856
running_loss:  1.2207335915461752
running_loss:  1.2875420760408613
running_loss:  1.3903518628374312
running_loss:  1.4252831313804362
running_loss:  1.4342670768544648
running_loss:  1.475441579587318
running_loss:  1.567994830078937
running_loss:  1.6009159270098383
running_loss:  1.6287370506098444
running_loss:  1.6482467513964771
running_loss:  1.667424214913303
running_loss:  1.7225921344425945
running_loss:  1.7435950305144718
running_loss:  1.8532879169862202
running_loss:  1.9119230597215293
running_loss:  1.9635753331175594
Epoch 60 of 80 Best Validation: 0.191137042978421 Time : 5307.849610328674


running_loss:  2.027692374999687
running_loss:  2.0741828411054386
running_loss:  2.1086923561071877
running_loss:  2.174941147192537
running_loss:  2.2015252951920656
running_loss:  2.2358884045776604
running_loss:  2.283044421191638
running_loss:  2.3490979383544377
running_loss:  2.3958702261766627
running_loss:  2.4862425725182726
running_loss:  2.527149226361265
running_loss:  2.607352543467035
running_loss:  2.65871559533601
running_loss:  2.745150063962986
running_loss:  2.795504778934022
running_loss:  2.8965232747917375
running_loss:  2.9498342893396816
running_loss:  2.9792667004900677
running_loss:  2.998019526279273
running_loss:  3.018428362424149

Train_err :  0.043120405177487844
totalValLoss:  2.5765121001232827
running_loss:  0.01291366381984618
running_loss:  0.061781168527280286
running_loss:  0.09754615020938218
running_loss:  0.14281154757676026
running_loss:  0.41781420594391727
running_loss:  0.4275426423021903
running_loss:  0.4824155361857266
running_loss:  0.5032249900590008
running_loss:  0.5294673500660186
running_loss:  0.551384194366013
running_loss:  0.5744472416117787
running_loss:  0.5945503831608221
running_loss:  0.6748680145246908
running_loss:  0.7229703039629385
running_loss:  0.7861426071031019
running_loss:  0.8108899696574857
running_loss:  0.8412114033320298
running_loss:  0.863326042269667
running_loss:  0.879555675201118
running_loss:  0.9353375697974116
running_loss:  0.9940822978969663
running_loss:  1.0261027586594638
running_loss:  1.1941602897778567
running_loss:  1.2030212184246112
Epoch 61 of 80 Best Validation: 0.191137042978421 Time : 5398.122818946838


running_loss:  1.222328620367787
running_loss:  1.2584052466425217
running_loss:  1.275000990057985
running_loss:  1.2915724566070519
running_loss:  1.3579184239594422
running_loss:  1.3844623757856123
running_loss:  1.4806889189737074
running_loss:  1.5448108880179159
running_loss:  1.6360063521521322
running_loss:  1.6647146049751125
running_loss:  1.762927353741058
running_loss:  1.7736627000946708
running_loss:  1.7918063569134879
running_loss:  1.8270182040772247
running_loss:  1.8612948113166365
running_loss:  1.878843783882783
running_loss:  1.8940500857780636
running_loss:  1.9109954846563697
running_loss:  1.9276648398081306
running_loss:  1.9448353066594184
running_loss:  1.9500984420786456
running_loss:  1.9669640359449354
running_loss:  2.0270859410035578
running_loss:  2.059863143241576
running_loss:  2.1044335183202443
running_loss:  2.1592123959659753
running_loss:  2.1884035435020146
running_loss:  2.2230326957877775
running_loss:  2.2525396727626985
running_loss:  2.281979379118032
running_loss:  2.3597201303249067
running_loss:  2.3850230227981224
running_loss:  2.431608693004818
running_loss:  2.458019106794381
running_loss:  2.467623726687937
running_loss:  2.502910567981113
running_loss:  2.509167078019042
running_loss:  2.518337676806065
running_loss:  2.5596999509337666
running_loss:  2.579118679122378
running_loss:  2.6058773703666196
running_loss:  2.622586502603048
running_loss:  2.691754436961168
running_loss:  2.7051018099688613
Epoch 62 of 80 Best Validation: 0.191137042978421 Time : 5476.1732766628265


running_loss:  2.7289170422203215
running_loss:  2.7489440784556787

Train_err :  0.03927062969222398
totalValLoss:  2.5229918290278874
running_loss:  0.023036109594007332
running_loss:  0.04956888866339189
running_loss:  0.07396600021941897
running_loss:  0.09632381729898043
running_loss:  0.11473587037956652
running_loss:  0.1397522659875297
running_loss:  0.16912649920171435
running_loss:  0.20204700567410325
running_loss:  0.211028539177884
running_loss:  0.22777058086163982
running_loss:  0.2578057508120158
running_loss:  0.302035840334914
running_loss:  0.3285372073587496
running_loss:  0.3604589174792636
running_loss:  0.3714578552462626
running_loss:  0.39943846928589566
running_loss:  0.41398496124182005
running_loss:  0.4380816400807817
running_loss:  0.5262428701680619
running_loss:  0.57158546357338
running_loss:  0.5935315434859755
running_loss:  0.6205038085075405
running_loss:  0.7228734150024441
running_loss:  0.7498390026739797
running_loss:  0.7719968207335719
running_loss:  0.854075776801134
running_loss:  0.8826327305804522
running_loss:  0.9407507014046939
running_loss:  0.9745956305931838
running_loss:  0.9886648199753834
running_loss:  1.0086073409959981
running_loss:  1.0701288338944623
running_loss:  1.1947069820210645
running_loss:  1.2139900656766256
running_loss:  1.230863423442416
running_loss:  1.3941818786616849
running_loss:  1.4220538990403937
running_loss:  1.4443114375527428
running_loss:  1.467336296740945
running_loss:  1.587633706335004
running_loss:  1.6032777422094817
running_loss:  1.613803628799764
Epoch 63 of 80 Best Validation: 0.191137042978421 Time : 5566.296521186829


running_loss:  1.6594245894100617
running_loss:  1.7880797548439453
running_loss:  1.8719322396662186
running_loss:  1.8981113618808898
running_loss:  1.920925692234757
running_loss:  1.9362756966697308
running_loss:  1.9599306572312745
running_loss:  1.9947472818538594
running_loss:  2.0167365902873113
running_loss:  2.0878736944707468
running_loss:  2.1058955720929786
running_loss:  2.137437709358184
running_loss:  2.1583593456016383
running_loss:  2.172253643068769
running_loss:  2.207315373140671
running_loss:  2.230567737679747
running_loss:  2.238014158524391
running_loss:  2.252779584866301
running_loss:  2.2826483717104153
running_loss:  2.299737447190434
running_loss:  2.309255632267902
running_loss:  2.3355983762756085
running_loss:  2.3650555003809526
running_loss:  2.390134665759331
running_loss:  2.403116594818937
running_loss:  2.4205232123430394
running_loss:  2.4416977367105157
running_loss:  2.4558417110626265

Train_err :  0.03508345301518038
totalValLoss:  2.465583420436208
running_loss:  0.010831711141185628
running_loss:  0.08689108982475267
running_loss:  0.10708168456201544
running_loss:  0.14303028634620002
running_loss:  0.24299708059859565
running_loss:  0.26747005514981637
running_loss:  0.34994524799468407
running_loss:  0.36459926871531123
running_loss:  0.4426400175499212
running_loss:  0.46232415170783897
running_loss:  0.5673783365022649
running_loss:  0.6620603445302953
running_loss:  0.6774533774360961
running_loss:  0.7189468142233736
running_loss:  0.7249242692454976
running_loss:  0.7386501280868994
Epoch 64 of 80 Best Validation: 0.191137042978421 Time : 5656.5537168979645


running_loss:  0.7532738050277759
running_loss:  0.7734121652772753
running_loss:  0.79044273178119
running_loss:  0.8109132764770441
running_loss:  0.8238191295111189
running_loss:  0.8416310940099517
running_loss:  0.8809304069889347
running_loss:  0.8982003943593655
running_loss:  0.9260547366057936
running_loss:  0.9373304963228293
running_loss:  0.9489708777303653
running_loss:  0.9874987873966651
running_loss:  0.9990281409894427
running_loss:  1.0882265887533626
running_loss:  1.1022046481278571
running_loss:  1.1136337097026021
running_loss:  1.1437310881204517
running_loss:  1.1661358079630495
running_loss:  1.2328263274151445
running_loss:  1.2623809482659758
running_loss:  1.282197170633784
running_loss:  1.3000167831827034
running_loss:  1.314966538072137
running_loss:  1.326656039324007
running_loss:  1.364247752300192
running_loss:  1.3843248043316028
running_loss:  1.4590544778960368
running_loss:  1.4775225882913219
running_loss:  1.494263508041816
running_loss:  1.5284122787626175
running_loss:  1.5339693778288266
running_loss:  1.5507215971997033
running_loss:  1.578648914545839
running_loss:  1.5883463751152804
running_loss:  1.6561099867895892
running_loss:  1.6682526152209094
running_loss:  1.6841271960503137
running_loss:  1.7493565299874818
running_loss:  1.7751939077877776
running_loss:  1.7837310193459013
running_loss:  1.8123915014520107
running_loss:  1.830385381473914
running_loss:  1.907858716442004
running_loss:  1.915425761992487
Epoch 65 of 80 Best Validation: 0.191137042978421 Time : 5734.578921556473


running_loss:  1.9487367499985138
running_loss:  1.9654098749953037
running_loss:  1.991471070358077
running_loss:  2.007724172269162
running_loss:  2.0127648796462583
running_loss:  2.033186280209015
running_loss:  2.05249940815621
running_loss:  2.068033481270605
running_loss:  2.085964918274031
running_loss:  2.100969997320337

Train_err :  0.030013857104576245
totalValLoss:  2.596852160278811
running_loss:  0.012193086173889848
running_loss:  0.02268573816885085
running_loss:  0.10589782323707671
running_loss:  0.1640708240496072
running_loss:  0.1795595156775865
running_loss:  0.2540701496230516
running_loss:  0.26375992762849715
running_loss:  0.2834476920527069
running_loss:  0.30585096648266896
running_loss:  0.32249170431007057
running_loss:  0.33772461574375884
running_loss:  0.42604104887545363
running_loss:  0.4380442324440486
running_loss:  0.44877523998406504
running_loss:  0.4637435456744343
running_loss:  0.4839877063414961
running_loss:  0.5383276255807787
running_loss:  0.553682615899662
running_loss:  0.5763034849240082
running_loss:  0.5878989967329996
running_loss:  0.6402966799958246
running_loss:  0.6518029636612885
running_loss:  0.655552657647705
running_loss:  0.6772703757128005
running_loss:  0.7553485488137488
running_loss:  0.774355747326303
running_loss:  0.7918985193213706
running_loss:  0.8179323426997547
running_loss:  0.8342709654793401
running_loss:  0.8646889083870013
running_loss:  0.8774807002110819
running_loss:  0.8972964391448637
running_loss:  0.9094561376227323
running_loss:  0.9280901348457617
Epoch 66 of 80 Best Validation: 0.191137042978421 Time : 5824.635611772537


running_loss:  0.972933290736465
running_loss:  0.9884073363953371
running_loss:  1.011858136613025
running_loss:  1.0264301612688638
running_loss:  1.0540612838877774
running_loss:  1.0865932829927054
running_loss:  1.091280376443238
running_loss:  1.1200981055363723
running_loss:  1.1366182835853473
running_loss:  1.1633256158561882
running_loss:  1.1791875013619166
running_loss:  1.205525112618084
running_loss:  1.2177249819845501
running_loss:  1.2257151575710543
running_loss:  1.251618311735607
running_loss:  1.26417000205159
running_loss:  1.2803460241169278
running_loss:  1.298162740844418
running_loss:  1.3163903341580103
running_loss:  1.4040462211657236
running_loss:  1.4204022788859825
running_loss:  1.434860634273112
running_loss:  1.4878871130107048
running_loss:  1.5094595212770703
running_loss:  1.523680387781092
running_loss:  1.5432709399012512
running_loss:  1.5554581596887955
running_loss:  1.6233436926639924
running_loss:  1.629362718239362
running_loss:  1.6411118490100813
running_loss:  1.6775222403408003
running_loss:  1.6899665876294927
running_loss:  1.6942257031122507
running_loss:  1.7097530132919525
running_loss:  1.7934878087431168
running_loss:  1.7993128167177526

Train_err :  0.02570446881025361
totalValLoss:  2.591931763021017
running_loss:  0.012012190340707699
running_loss:  0.0285840669595119
running_loss:  0.03994063758161953
running_loss:  0.06749020358418217
running_loss:  0.07923178321086904
running_loss:  0.11854000335895559
running_loss:  0.16916916838252088
running_loss:  0.17690028799956456
Epoch 67 of 80 Best Validation: 0.191137042978421 Time : 5914.905807256699


running_loss:  0.18955000465373611
running_loss:  0.21203494326780653
running_loss:  0.22333010556435004
running_loss:  0.23552296381159166
running_loss:  0.23904258410200577
running_loss:  0.2500686969918509
running_loss:  0.32071532572930056
running_loss:  0.33003027287971537
running_loss:  0.3476655636234985
running_loss:  0.3579730067188696
running_loss:  0.37088325196398525
running_loss:  0.4100885572422865
running_loss:  0.4282770615116331
running_loss:  0.43591847910688053
running_loss:  0.4906053085546268
running_loss:  0.5015410917662343
running_loss:  0.5116432311123289
running_loss:  0.5261342048405722
running_loss:  0.5533847293150352
running_loss:  0.5678197415965971
running_loss:  0.5738206416750068
running_loss:  0.6509122386956329
running_loss:  0.6689001864999429
running_loss:  0.678012633178797
running_loss:  0.7016819389019575
running_loss:  0.7652184375975695
running_loss:  0.7867105630640354
running_loss:  0.7998083058983967
running_loss:  0.8297367219121143
running_loss:  0.8469589012060573
running_loss:  0.8678705631140878
running_loss:  0.8839398117237983
running_loss:  0.8955981780034361
running_loss:  0.9142773769676246
running_loss:  0.93343009737469
running_loss:  0.9499507794373332
running_loss:  0.9833558449738322
running_loss:  1.0011587945029734
running_loss:  1.0098299214425626
running_loss:  1.04122093113094
running_loss:  1.0647947180825414
running_loss:  1.1569549206453504
running_loss:  1.1698206338898873
running_loss:  1.2005094531325287
Epoch 68 of 80 Best Validation: 0.191137042978421 Time : 5992.868440151215


running_loss:  1.210462042691587
running_loss:  1.235591371871932
running_loss:  1.2731590879638033
running_loss:  1.3305079390783148
running_loss:  1.3498140779346512
running_loss:  1.3625357072952384
running_loss:  1.3769373606790194
running_loss:  1.387584488064426
running_loss:  1.39510777701475
running_loss:  1.4079494179960523
running_loss:  1.4114477722533696
running_loss:  1.4213860889253234
running_loss:  1.4636810670894598
running_loss:  1.5182850274545168
running_loss:  1.532623687838269
running_loss:  1.5434696215929258
running_loss:  1.554844561032951
running_loss:  1.5795585783198478

Train_err :  0.022565122547426396
totalValLoss:  2.6923509809744752
running_loss:  0.014177374541759491
running_loss:  0.07009034976363182
running_loss:  0.09133225306868553
running_loss:  0.11252921586856246
running_loss:  0.11973277239788634
running_loss:  0.12715001164017142
running_loss:  0.13748668491542856
running_loss:  0.15132715176959108
running_loss:  0.16773378093946828
running_loss:  0.18456173685909663
running_loss:  0.19332314704661258
running_loss:  0.2115073120512534
running_loss:  0.2776721110858489
running_loss:  0.28996160136496957
running_loss:  0.3002214706793893
running_loss:  0.30287369855795987
running_loss:  0.33421664183454897
running_loss:  0.343435951557088
running_loss:  0.4336844841503383
running_loss:  0.5085929027312279
running_loss:  0.534049664265088
running_loss:  0.5402806458199241
running_loss:  0.5605474191349155
running_loss:  0.5794381470574687
running_loss:  0.6014369575875914
running_loss:  0.6174762906804163
Epoch 69 of 80 Best Validation: 0.191137042978421 Time : 6083.0271372795105


running_loss:  0.6234913927392982
running_loss:  0.6318580348322737
running_loss:  0.6445167457342096
running_loss:  0.6485739599366853
running_loss:  0.706077198257036
running_loss:  0.7539632196922967
running_loss:  0.7611999867674765
running_loss:  0.778681161087459
running_loss:  0.7892678553439003
running_loss:  0.7997349335702083
running_loss:  0.8193905720998169
running_loss:  0.8331151863450131
running_loss:  0.9072497522348485
running_loss:  0.929895685788425
running_loss:  0.9466656114640903
running_loss:  0.9511540894131434
running_loss:  0.9611642368706977
running_loss:  0.9728999957797997
running_loss:  0.9977347832528822
running_loss:  1.0184644923202641
running_loss:  1.0740235910408147
running_loss:  1.1092390822660592
running_loss:  1.1295076547604468
running_loss:  1.1418706429119792
running_loss:  1.175177793823726
running_loss:  1.190437791820538
running_loss:  1.2102376165987356
running_loss:  1.2336407956544364
running_loss:  1.2404478188481236
running_loss:  1.2607255634728873
running_loss:  1.278611433203979
running_loss:  1.2944903578770919
running_loss:  1.2982222048319982
running_loss:  1.3106220218728093
running_loss:  1.3224050098667959
running_loss:  1.3959163793931821
running_loss:  1.4131326839819347
running_loss:  1.4284120649649092
running_loss:  1.4390239339619362
running_loss:  1.4547301998213196
running_loss:  1.465748511707514
running_loss:  1.5111449812409574
running_loss:  1.5282303527799541
running_loss:  1.5422523871691538

Train_err :  0.02203217695955934
totalValLoss:  2.7270624874314913
Epoch 70 of 80 Best Validation: 0.191137042978421 Time : 6173.343279838562


running_loss:  0.011956341719875732
running_loss:  0.0393333399357895
running_loss:  0.04771531016255418
running_loss:  0.056616922749930784
running_loss:  0.09715080159043686
running_loss:  0.10776612852027433
running_loss:  0.1301025500546934
running_loss:  0.13539877241095788
running_loss:  0.14753155364532078
running_loss:  0.164007343942002
running_loss:  0.2144456139148032
running_loss:  0.23008821506745236
running_loss:  0.2382830581805643
running_loss:  0.24924506859032491
running_loss:  0.2934646108850656
running_loss:  0.3075462575733481
running_loss:  0.335354294694197
running_loss:  0.3390659127455567
running_loss:  0.3542501400968629
running_loss:  0.4217211600205499
running_loss:  0.43788194761469235
running_loss:  0.4573029644121157
running_loss:  0.46463495923995246
running_loss:  0.47921061837243745
running_loss:  0.5348026039557428
running_loss:  0.544162191313161
running_loss:  0.5783504660875122
running_loss:  0.6025148603302012
running_loss:  0.6166906240768083
running_loss:  0.6495207749232779
running_loss:  0.672345096098272
running_loss:  0.717880805807201
running_loss:  0.7300975248686478
running_loss:  0.7441108053398138
running_loss:  0.7567790281884502
running_loss:  0.7671619455294503
running_loss:  0.7820050753442855
running_loss:  0.7973820484654021
running_loss:  0.8029659106088931
running_loss:  0.8244851265416299
running_loss:  0.8318539013481413
running_loss:  0.8496492245095496
running_loss:  0.8609975256662841
running_loss:  0.876736006287198
Epoch 71 of 80 Best Validation: 0.191137042978421 Time : 6251.474799633026


running_loss:  0.8886479368035602
running_loss:  0.9200392047011214
running_loss:  0.9374339537995788
running_loss:  0.9515271822989839
running_loss:  0.9643466184449303
running_loss:  0.9797535418426073
running_loss:  1.0052895258074082
running_loss:  1.0135132685326322
running_loss:  1.0449677801597215
running_loss:  1.060655848820008
running_loss:  1.0736254763792705
running_loss:  1.0905191527579312
running_loss:  1.1542145760629658
running_loss:  1.1707854482245033
running_loss:  1.2198018531214778
running_loss:  1.236459042587537
running_loss:  1.2752303180184548
running_loss:  1.2867216991936499
running_loss:  1.2952138353866753
running_loss:  1.3122873693500874
running_loss:  1.3199958054481407
running_loss:  1.3290068054743134
running_loss:  1.3721545947887026
running_loss:  1.3885837915214423
running_loss:  1.40580213636632
running_loss:  1.4520342555689338

Train_err :  0.020743346508127626
totalValLoss:  2.762902162529321
running_loss:  0.013493928369522715
running_loss:  0.016440460099450622
running_loss:  0.07171549053358224
running_loss:  0.08444873345433734
running_loss:  0.1416651542240288
running_loss:  0.16102806638809852
running_loss:  0.16424255160382017
running_loss:  0.17701797561797625
running_loss:  0.186280812350257
running_loss:  0.1997067194703656
running_loss:  0.20988233345269694
running_loss:  0.22191021101025402
running_loss:  0.23201181929713738
running_loss:  0.2556393047755895
running_loss:  0.2688844679246864
running_loss:  0.2782144571570421
running_loss:  0.2860168215734626
running_loss:  0.2982138921442028
Epoch 72 of 80 Best Validation: 0.191137042978421 Time : 6341.526665210724


running_loss:  0.3131897724168893
running_loss:  0.3170778107095329
running_loss:  0.3198228622770532
running_loss:  0.3741090069508775
running_loss:  0.3837095751692282
running_loss:  0.3895504601564931
running_loss:  0.4458844453361558
running_loss:  0.5221629455950784
running_loss:  0.5372669247865107
running_loss:  0.5542207316450205
running_loss:  0.559580754763576
running_loss:  0.5679125143053372
running_loss:  0.6168311899366219
running_loss:  0.6306337197408235
running_loss:  0.6423912203366247
running_loss:  0.6494212127323002
running_loss:  0.660858402681899
running_loss:  0.6886473416363715
running_loss:  0.7006196558035701
running_loss:  0.7120431797391371
running_loss:  0.7581640953010516
running_loss:  0.7847793240281234
running_loss:  0.7983318244967246
running_loss:  0.823841167073826
running_loss:  0.8452889382250657
running_loss:  0.8621163987877983
running_loss:  0.8755772943291552
running_loss:  0.8979674141381917
running_loss:  0.91131836738916
running_loss:  0.9193116109139129
running_loss:  0.9618943463331863
running_loss:  0.9809115670407965
running_loss:  1.0032347777644945
running_loss:  1.0193741373271523
running_loss:  1.0383630607296555
running_loss:  1.061462461298409
running_loss:  1.0782350389539106
running_loss:  1.0816184626795193
running_loss:  1.0931323681434149
running_loss:  1.105992823053384
running_loss:  1.1152125528509105
running_loss:  1.128656894744684
running_loss:  1.1372293052263556
running_loss:  1.1553440359421072
Epoch 73 of 80 Best Validation: 0.191137042978421 Time : 6419.574327707291


running_loss:  1.1645013803936306
running_loss:  1.1713466042791776
running_loss:  1.179356233803749
running_loss:  1.229447422204733
running_loss:  1.2698385488523245
running_loss:  1.287680504499197
running_loss:  1.306125545064181
running_loss:  1.3090130550602526

Train_err :  0.01870018650086075
totalValLoss:  2.7331110454655976
running_loss:  0.01342317822854966
running_loss:  0.028520471998490393
running_loss:  0.03822708590370086
running_loss:  0.051487558935251504
running_loss:  0.05565850152116683
running_loss:  0.06952422286202717
running_loss:  0.08454300427628267
running_loss:  0.12296852433872926
running_loss:  0.12994702404830605
running_loss:  0.14464811235666275
running_loss:  0.1587570886282871
running_loss:  0.1691645027603954
running_loss:  0.17960570170544088
running_loss:  0.1863208047579974
running_loss:  0.1994010841687365
running_loss:  0.2093501996843972
running_loss:  0.2312591360176965
running_loss:  0.254299375949712
running_loss:  0.2716639813831231
running_loss:  0.3371074077537438
running_loss:  0.3747050714543244
running_loss:  0.3898607430843791
running_loss:  0.40017428496503266
running_loss:  0.4121834460335473
running_loss:  0.4221630408428609
running_loss:  0.4322000670266182
running_loss:  0.4422689844068372
running_loss:  0.49008143880928395
running_loss:  0.5436065141257131
running_loss:  0.5475727679877309
running_loss:  0.5590822458276913
running_loss:  0.5679269480072737
running_loss:  0.5811011995247098
running_loss:  0.5890469851243929
running_loss:  0.5934629806094258
running_loss:  0.6047001029025219
Epoch 74 of 80 Best Validation: 0.191137042978421 Time : 6509.675926685333


running_loss:  0.6137049801683233
running_loss:  0.6212019643781886
running_loss:  0.6281040132534043
running_loss:  0.6480352942388788
running_loss:  0.6507879165276083
running_loss:  0.6696103848961582
running_loss:  0.683408353784115
running_loss:  0.7325067709470102
running_loss:  0.7424081211558788
running_loss:  0.7453826843856303
running_loss:  0.78895554236159
running_loss:  0.7991265749013917
running_loss:  0.8102528961567763
running_loss:  0.8150949260412339
running_loss:  0.826286875299249
running_loss:  0.8395028911820391
running_loss:  0.8543918901179696
running_loss:  0.8873508661110664
running_loss:  0.8990589975979268
running_loss:  0.9178868732083678
running_loss:  0.9301244217777921
running_loss:  0.9412176815668417
running_loss:  0.9513735821423728
running_loss:  0.9616012663261951
running_loss:  0.9755184041560925
running_loss:  0.9858188352170852
running_loss:  0.9898859181064633
running_loss:  1.0020612635893889
running_loss:  1.0100498701301854
running_loss:  1.0170094977584083
running_loss:  1.0683418150510986
running_loss:  1.0744077791031383
running_loss:  1.0913242762479864
running_loss:  1.1190888406280362

Train_err :  0.015986983437543373
totalValLoss:  2.895764332394012
running_loss:  0.011081590989811553
running_loss:  0.020571329983391076
running_loss:  0.031237994614962697
running_loss:  0.08086606610191262
running_loss:  0.08918437736509885
running_loss:  0.10108297599880542
running_loss:  0.1094662473414145
running_loss:  0.11793239962167314
running_loss:  0.16997576679892112
running_loss:  0.1801543177991536
Epoch 75 of 80 Best Validation: 0.191137042978421 Time : 6599.772339582443


running_loss:  0.18599500674301653
running_loss:  0.20360907532287656
running_loss:  0.2095317533336735
running_loss:  0.22058007136608163
running_loss:  0.22317218851336898
running_loss:  0.22543263042462058
running_loss:  0.26619712615502067
running_loss:  0.2763337761037595
running_loss:  0.28042093628513004
running_loss:  0.3262492079423585
running_loss:  0.3348397420906824
running_loss:  0.3467056457722922
running_loss:  0.3771661030898233
running_loss:  0.38636778393023025
running_loss:  0.40122246234871756
running_loss:  0.4105792740447214
running_loss:  0.4196710726941496
running_loss:  0.4256840344282359
running_loss:  0.4699257571014136
running_loss:  0.4798042373068812
running_loss:  0.49207572539227035
running_loss:  0.5032677768823406
running_loss:  0.5160378826953497
running_loss:  0.5303899888353448
running_loss:  0.547115132109967
running_loss:  0.5595524395701229
running_loss:  0.5783772506636321
running_loss:  0.5853598096396632
running_loss:  0.5960148374538726
running_loss:  0.6020030416071273
running_loss:  0.6109629666469927
running_loss:  0.6221623031136309
running_loss:  0.6323636779585893
running_loss:  0.644530852327686
running_loss:  0.6540402502311433
running_loss:  0.6974148370815481
running_loss:  0.7061364500283769
running_loss:  0.7553079797386697
running_loss:  0.7628702827714734
running_loss:  0.7750800309222542
running_loss:  0.7822500797362106
running_loss:  0.791810920580853
running_loss:  0.8008828119612493
running_loss:  0.8082744687101998
Epoch 76 of 80 Best Validation: 0.191137042978421 Time : 6677.937890529633


running_loss:  0.8167635162074779
running_loss:  0.824807753119482
running_loss:  0.8316744335825207
running_loss:  0.8380135927945959
running_loss:  0.8789014030844556
running_loss:  0.9237781424671995
running_loss:  0.9336163674767401
running_loss:  0.9416536020895971
running_loss:  0.9470711706081704
running_loss:  0.9636284427558874
running_loss:  0.9768754735430574
running_loss:  0.9860329832024743
running_loss:  0.9964181706551851
running_loss:  1.0050527919455716
running_loss:  1.020714138875418
running_loss:  1.0275404689099459

Train_err :  0.01467914955585637
totalValLoss:  2.9867296788789743
running_loss:  0.0093526039175534
running_loss:  0.06494441813750503
running_loss:  0.08237167097589311
running_loss:  0.10219679608902273
running_loss:  0.14908788934311207
running_loss:  0.16146254422104295
running_loss:  0.17829314362218912
running_loss:  0.18983903348432957
running_loss:  0.19880306169377743
running_loss:  0.20689452100325273
running_loss:  0.21548260839416697
running_loss:  0.21838508519997252
running_loss:  0.23055956144364448
running_loss:  0.2412664653853022
running_loss:  0.24499912552305939
running_loss:  0.2552759328350981
running_loss:  0.26554737344445634
running_loss:  0.2750689513931219
running_loss:  0.2802102641152386
running_loss:  0.29416797994134763
running_loss:  0.2968777151747619
running_loss:  0.31270273718675723
running_loss:  0.32252475160849925
running_loss:  0.32977773515368525
running_loss:  0.3429853498083604
running_loss:  0.3821735560041917
running_loss:  0.41284526335867766
running_loss:  0.41983751590224627
Epoch 77 of 80 Best Validation: 0.191137042978421 Time : 6768.0124180316925


running_loss:  0.42870892971809044
running_loss:  0.4582440146809353
running_loss:  0.4660558231351185
running_loss:  0.4801768481209162
running_loss:  0.48925968075652937
running_loss:  0.5030339271995924
running_loss:  0.5110877835775479
running_loss:  0.5205003444320431
running_loss:  0.5481194427451959
running_loss:  0.5557655957664892
running_loss:  0.5664899429676652
running_loss:  0.5725788591411805
running_loss:  0.5823267451042838
running_loss:  0.5921908539061809
running_loss:  0.6014947450061703
running_loss:  0.6430463312467003
running_loss:  0.6549511074206545
running_loss:  0.6607296888161929
running_loss:  0.6688890572056859
running_loss:  0.6816346217375313
running_loss:  0.6842103219136738
running_loss:  0.6898347377322757
running_loss:  0.6983117408324486
running_loss:  0.7125339947613409
running_loss:  0.7593078829320601
running_loss:  0.7679764315148027
running_loss:  0.7790669265127185
running_loss:  0.790931831001621
running_loss:  0.7980310196427227
running_loss:  0.8111235123497964
running_loss:  0.8210056659437315
running_loss:  0.8261461646963855
running_loss:  0.83724719264703
running_loss:  0.8438867128190597
running_loss:  0.851357357106786
running_loss:  0.858997325379783
running_loss:  0.8665869551583051
running_loss:  0.9117869528814077
running_loss:  0.9216486084793966
running_loss:  0.926023746508387
running_loss:  0.9285573630356035
running_loss:  0.9491511724651597

Train_err :  0.013559302463787995
totalValLoss:  2.990783582713144
running_loss:  0.016664243305664666
running_loss:  0.06509813200924934
Epoch 78 of 80 Best Validation: 0.191137042978421 Time : 6858.2937271595


running_loss:  0.07667234946388313
running_loss:  0.08366795076856054
running_loss:  0.14034874929913915
running_loss:  0.1616439759567988
running_loss:  0.1717569453604584
running_loss:  0.18242607324322713
running_loss:  0.21368786890929592
running_loss:  0.2278307441972882
running_loss:  0.24328009485826546
running_loss:  0.24695912374510148
running_loss:  0.26199245389256653
running_loss:  0.31827844615731415
running_loss:  0.333655403955264
running_loss:  0.3446112526281569
running_loss:  0.35540765233761507
running_loss:  0.4093999721897288
running_loss:  0.438610077728097
running_loss:  0.48911982763982254
running_loss:  0.5024991422566625
running_loss:  0.5197959375242742
running_loss:  0.5767861661176237
running_loss:  0.6377239879827055
running_loss:  0.6539019744304825
running_loss:  0.6637750856583202
running_loss:  0.6689224105333174
running_loss:  0.6840067184069389
running_loss:  0.6925761146291433
running_loss:  0.7105523188001828
running_loss:  0.7231162570751624
running_loss:  0.7651722289956526
running_loss:  0.7718650964436369
running_loss:  0.7884264738879414
running_loss:  0.7991875250065481
running_loss:  0.8133707165891086
running_loss:  0.8247186519980058
running_loss:  0.8324515112577099
running_loss:  0.8474982526054698
running_loss:  0.857221310782835
running_loss:  0.8596999440722156
running_loss:  0.8706416487637197
running_loss:  0.8810656391667889
running_loss:  0.8911815120704383
running_loss:  0.8992030002158977
running_loss:  0.9015852427635563
Epoch 79 of 80 Best Validation: 0.191137042978421 Time : 6936.418885231018


running_loss:  0.911048188547688
running_loss:  0.9501999390526585
running_loss:  0.9661689270037137
running_loss:  0.9684057543385685
running_loss:  0.9790725963434348
running_loss:  0.9866307225982182
running_loss:  0.99389343976428
running_loss:  1.0026693475657442
running_loss:  1.012148270570227
running_loss:  1.0199046821532345
running_loss:  1.0308730453277046
running_loss:  1.0366847082065458
running_loss:  1.0515786435013676
running_loss:  1.058131227285129
running_loss:  1.0709878550996008
running_loss:  1.0846392482110079
running_loss:  1.094504460290611
running_loss:  1.1042071021519304
running_loss:  1.1141754369996812
running_loss:  1.1206437948025674
running_loss:  1.137961092670998
running_loss:  1.1415850649540922
running_loss:  1.1732739693438312
running_loss:  1.2159263416146537

Train_err :  0.017370376308780768
totalValLoss:  2.9701548747511373
running_loss:  0.015584717155434191
running_loss:  0.025347077869810164
running_loss:  0.04392354902423297
running_loss:  0.051841251697624095
running_loss:  0.054973808941819385
running_loss:  0.06068851555270763
running_loss:  0.06821179261573382
running_loss:  0.08322441511619318
running_loss:  0.10001357486665557
running_loss:  0.11353696750302332
running_loss:  0.16194219009776134
running_loss:  0.18414758758444805
running_loss:  0.19836327138182241
running_loss:  0.2078527853494355
running_loss:  0.26037036335522623
running_loss:  0.2711242561830053
running_loss:  0.28625756978484185
running_loss:  0.29863094615737085
running_loss:  0.30772507191027726
running_loss:  0.35280082002605523
Epoch 80 of 80 Best Validation: 0.191137042978421 Time : 7026.510474205017


Finished Training in 7026.510479450226s
Train error array :  [0.37821343 0.29687332 0.29615973 0.3150773  0.29021844 0.26881454
 0.27435354 0.27379546 0.26866304 0.24666056 0.2467428  0.22423328
 0.2267893  0.21644049 0.23576989 0.22680025 0.20149116 0.21460716
 0.20280976 0.18998122 0.18515502 0.17232581 0.16964023 0.17710102
 0.16569299 0.14353995 0.14649078 0.12082537 0.14877552 0.12675807
 0.10529837 0.09765534 0.10103088 0.13300313 0.07527198 0.06011468
 0.05341223 0.04312041 0.03927063 0.03508345 0.03001386 0.02570447
 0.02256512 0.02203218 0.02074335 0.01870019 0.01598698 0.01467915
 0.0135593  0.01737038]
Validation error array :  [0.36595412 0.3526079  0.33988279 0.33667245 0.34832124 0.3320046
 0.30548662 0.29561336 0.30056651 0.29692262 0.27044774 0.28217867
 0.30266021 0.2877193  0.2771489  0.25093172 0.29075289 0.24355835
 0.26978175 0.24497445 0.25220849 0.23950605 0.25272749 0.22771528
 0.24289329 0.2242839  0.22532555 0.21966024 0.29585013 0.22097375
 0.2090549  0.20970372 0.26419827 0.19113704 0.21133276 0.22130924
 0.22289654 0.23422837 0.22936289 0.22414395 0.23607747 0.23563016
 0.24475918 0.24791477 0.25117292 0.24846464 0.2632513  0.27152088
 0.27188942 0.27001408]
Sample  array :  [  70.  140.  210.  280.  350.  420.  490.  560.  630.  700.  770.  840.
  910.  980. 1050. 1120. 1190. 1260. 1330. 1400. 1470. 1540. 1610. 1680.
 1750. 1820. 1890. 1960. 2030. 2100. 2170. 2240. 2310. 2380. 2450. 2520.
 2590. 2660. 2730. 2800. 2870. 2940. 3010. 3080. 3150. 3220. 3290. 3360.
 3430. 3500.]
