{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Demo_soutenance.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "brD29x_Agi5s"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Notebook pour le test de modèle pour le PTRANS**\n",
        "\n",
        "☕*Created by :*\n",
        "\n",
        "*   Mattéo Boursault\n",
        "*   Ibrahim Braham\n",
        "*   Adam Creusevault\n",
        "\n",
        "Dernière modification : *18/05/2022*\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "aY0pGh6GhKic"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Import + Connexion au Drive + Modèle"
      ],
      "metadata": {
        "id": "brD29x_Agi5s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install albumentations==0.4.6\n",
        "!pip install torchinfo\n",
        "\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from PIL import Image\n",
        "import albumentations as A\n",
        "import cv2\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import copy\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "nztY-_BKaSc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# modele UNet :\n",
        "\n",
        "class DoubleConv(nn.Module):\n",
        "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
        "        super().__init__()\n",
        "        if not mid_channels:\n",
        "            mid_channels = out_channels\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(mid_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "\n",
        "class Down(nn.Module):\n",
        "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.maxpool_conv = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            DoubleConv(in_channels, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.maxpool_conv(x)\n",
        "\n",
        "\n",
        "class Up(nn.Module):\n",
        "    \"\"\"Transposed convolution then double conv\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.up = nn.ConvTranspose2d(in_channels , out_channels, kernel_size=2, stride=2)\n",
        "        self.conv = DoubleConv(in_channels, out_channels)\n",
        "\n",
        "\n",
        "    def forward_padding(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        # input is CHW\n",
        "        diffY = x2.size()[2] - x1.size()[2]\n",
        "        diffX = x2.size()[3] - x1.size()[3]\n",
        "\n",
        "        x1 = nn.functionnal.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
        "                        diffY // 2, diffY - diffY // 2])\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        return self.conv(x)\n",
        "\n",
        "    def forward(self, target_tensor, contracting_tensor):\n",
        "        target_tensor = self.up(target_tensor)\n",
        "        target_height = target_tensor.size()[2]\n",
        "        target_width = target_tensor.size()[3]\n",
        "        crop = transforms.CenterCrop((target_height, target_width))\n",
        "\n",
        "        contracting_tensor = crop(contracting_tensor)\n",
        "        new_tensor = torch.cat((target_tensor, contracting_tensor), 1)\n",
        "\n",
        "        return self.conv(new_tensor)\n",
        "\n",
        "\n",
        "class OutConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(OutConv, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_channels, n_classes):\n",
        "        super(UNet, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "\n",
        "        self.inc = DoubleConv(n_channels, 64)\n",
        "        self.down1 = Down(64, 128)\n",
        "        self.down2 = Down(128, 256)\n",
        "        self.down3 = Down(256, 512)\n",
        "        self.down4 = Down(512, 1024)\n",
        "        self.up1 = Up(1024, 512)\n",
        "        self.up2 = Up(512, 256)\n",
        "        self.up3 = Up(256, 128)\n",
        "        self.up4 = Up(128, 64)\n",
        "        self.outc = OutConv(64, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        x = self.up1(x5, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        logits = self.outc(x)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "iVT7OqrNggta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Configuration"
      ],
      "metadata": {
        "id": "YzzW1WJJkIj9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "- Complétez les chemins\n",
        "- Executez toutes les cellules du Notebook\n",
        "- Have fun\n",
        "'''\n",
        "\n",
        "IMG_PATH = \"drive/MyDrive/soutenance/radio_1.jpg\"\n",
        "MODEL_PATH = 'drive/MyDrive/soutenance/model.pth'\n",
        "RESIZING_SIZE = 1024"
      ],
      "metadata": {
        "id": "LtMHuc2MhbMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Test du modèle"
      ],
      "metadata": {
        "id": "iNcgZfpMg6V9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For testing new image : complete path\n",
        "\n",
        "# Load the model\n",
        "model = UNet(1, 4)\n",
        "model_to_test = torch.load(MODEL_PATH)\n",
        "model.load_state_dict(model_to_test[\"model_state_dict\"])\n",
        "model.eval()\n",
        "model.to(\"cuda\")\n",
        "\n",
        "radio = np.array(Image.open(IMG_PATH))\n",
        "\n",
        "# Resizing\n",
        "validation_transform = A.Compose([\n",
        "    A.LongestMaxSize(RESIZING_SIZE),\n",
        "    A.PadIfNeeded(min_height=RESIZING_SIZE, min_width=RESIZING_SIZE, border_mode=cv2.BORDER_CONSTANT),\n",
        "])\n",
        "radio = validation_transform(image=radio)['image']\n",
        "\n",
        "# Grayscale\n",
        "grayscale_transform = transforms.Compose([transforms.Grayscale(num_output_channels=1), transforms.ToTensor()])\n",
        "radio = Image.fromarray(radio)\n",
        "radio = grayscale_transform(radio)\n",
        "\n",
        "output = model(radio.unsqueeze(1).to(\"cuda\"))\n",
        "output = output[0].cpu().data.numpy()\n",
        "index = output.argmax(axis=0)\n",
        "\n",
        "figure, ax = plt.subplots(ncols=2, figsize=(10, 40))\n",
        "ax[0].imshow(radio[0])\n",
        "ax[1].imshow(index*100)\n",
        "\n",
        "ax[0].set_title(\"Image: \", fontsize=20)\n",
        "ax[1].set_title(\"predicted mask: \", fontsize=20)\n",
        "\n",
        "ax[0].set_axis_off()\n",
        "ax[1].set_axis_off()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "QSnS7n4Qaf7t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}